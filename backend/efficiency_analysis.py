#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
íš¨ìœ¨ì„± ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- ê° ê¸°ëŠ¥ë³„ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ ì¸¡ì •
- ìºì‹œ íš¨ìœ¨ì„± ë¶„ì„
- ë¹„ë™ê¸° ì²˜ë¦¬ íš¨ê³¼ ë¶„ì„
"""

import time
import asyncio
from typing import List, Dict
from crawler import search_ssg_products_legacy, search_ssg_products
from cache_manager import cache_manager

class EfficiencyAnalyzer:
    """íš¨ìœ¨ì„± ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.results = {}
    
    def test_sync_vs_async(self, keyword: str, limit: int = 5) -> Dict:
        """ë™ê¸° vs ë¹„ë™ê¸° ì„±ëŠ¥ ë¹„êµ"""
        print(f"ğŸ” '{keyword}' ë™ê¸° vs ë¹„ë™ê¸° ì„±ëŠ¥ ë¹„êµ")
        print("-" * 50)
        
        # ìºì‹œ ì´ˆê¸°í™”
        cache_manager.clear_cache()
        
        # 1. ë™ê¸° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
        print("ğŸŒ ë™ê¸° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸...")
        start_time = time.time()
        
        try:
            sync_results = search_ssg_products_legacy(keyword, limit=limit)
            sync_time = time.time() - start_time
            sync_count = len(sync_results)
            print(f"   ì™„ë£Œ: {sync_time:.2f}ì´ˆ, {sync_count}ê°œ ìƒí’ˆ")
        except Exception as e:
            print(f"   ì˜¤ë¥˜: {e}")
            sync_time = 0
            sync_count = 0
        
        # ì ì‹œ ëŒ€ê¸°
        time.sleep(1)
        
        # ìºì‹œ ì´ˆê¸°í™”
        cache_manager.clear_cache()
        
        # 2. ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
        print("ğŸš€ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸...")
        start_time = time.time()
        
        try:
            async_results = search_ssg_products(keyword, limit=limit)
            async_time = time.time() - start_time
            async_count = len(async_results)
            print(f"   ì™„ë£Œ: {async_time:.2f}ì´ˆ, {async_count}ê°œ ìƒí’ˆ")
        except Exception as e:
            print(f"   ì˜¤ë¥˜: {e}")
            async_time = 0
            async_count = 0
        
        # ì„±ëŠ¥ ê°œì„  ê³„ì‚°
        if sync_time > 0 and async_time > 0:
            improvement = ((sync_time - async_time) / sync_time) * 100
            speed_ratio = sync_time / async_time
            print(f"ğŸ“ˆ ì„±ëŠ¥ ê°œì„ : {improvement:.1f}%")
            print(f"âš¡ ì†ë„ ë¹„ìœ¨: {speed_ratio:.1f}x ë¹ ë¦„")
        else:
            improvement = 0
            speed_ratio = 1
        
        return {
            'keyword': keyword,
            'sync_time': sync_time,
            'async_time': async_time,
            'sync_count': sync_count,
            'async_count': async_count,
            'improvement_percent': improvement,
            'speed_ratio': speed_ratio
        }
    
    def test_cache_efficiency(self, keyword: str, limit: int = 5) -> Dict:
        """ìºì‹œ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ’¾ '{keyword}' ìºì‹œ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸")
        print("-" * 50)
        
        # ìºì‹œ ì´ˆê¸°í™”
        cache_manager.clear_cache()
        
        # 1. ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ì—†ìŒ)
        print("1ï¸âƒ£ ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ì—†ìŒ)...")
        start_time = time.time()
        first_results = search_ssg_products(keyword, limit=limit)
        first_time = time.time() - start_time
        print(f"   ì™„ë£Œ: {first_time:.2f}ì´ˆ, {len(first_results)}ê°œ ìƒí’ˆ")
        
        # 2. ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ìˆìŒ)
        print("2ï¸âƒ£ ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ìˆìŒ)...")
        start_time = time.time()
        cached_results = search_ssg_products(keyword, limit=limit)
        cached_time = time.time() - start_time
        print(f"   ì™„ë£Œ: {cached_time:.2f}ì´ˆ, {len(cached_results)}ê°œ ìƒí’ˆ")
        
        # ìºì‹œ íš¨ìœ¨ì„± ê³„ì‚°
        if first_time > 0:
            cache_improvement = ((first_time - cached_time) / first_time) * 100
            cache_speed_ratio = first_time / cached_time if cached_time > 0 else float('inf')
            print(f"ğŸ’¨ ìºì‹œ ê°œì„ : {cache_improvement:.1f}%")
            print(f"âš¡ ìºì‹œ ì†ë„: {cache_speed_ratio:.1f}x ë¹ ë¦„")
        else:
            cache_improvement = 0
            cache_speed_ratio = 1
        
        # 3. ì—¬ëŸ¬ ë²ˆ ìš”ì²­í•˜ì—¬ ìºì‹œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
        print("3ï¸âƒ£ ìºì‹œ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (5íšŒ ìš”ì²­)...")
        cache_times = []
        
        for i in range(5):
            start_time = time.time()
            search_ssg_products(keyword, limit=limit)
            cache_times.append(time.time() - start_time)
        
        avg_cache_time = sum(cache_times) / len(cache_times)
        max_cache_time = max(cache_times)
        min_cache_time = min(cache_times)
        
        print(f"   í‰ê· : {avg_cache_time:.3f}ì´ˆ")
        print(f"   ìµœì†Œ: {min_cache_time:.3f}ì´ˆ")
        print(f"   ìµœëŒ€: {max_cache_time:.3f}ì´ˆ")
        
        return {
            'keyword': keyword,
            'first_time': first_time,
            'cached_time': cached_time,
            'cache_improvement_percent': cache_improvement,
            'cache_speed_ratio': cache_speed_ratio,
            'avg_cache_time': avg_cache_time,
            'cache_stability': max_cache_time - min_cache_time
        }
    
    def test_concurrent_requests(self, keywords: List[str], limit: int = 3) -> Dict:
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ”¥ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
        print(f"í‚¤ì›Œë“œ: {keywords}")
        print("-" * 50)
        
        # ìºì‹œ ì´ˆê¸°í™”
        cache_manager.clear_cache()
        
        # 1. ìˆœì°¨ ì²˜ë¦¬
        print("1ï¸âƒ£ ìˆœì°¨ ì²˜ë¦¬...")
        start_time = time.time()
        
        sequential_results = []
        for keyword in keywords:
            results = search_ssg_products(keyword, limit=limit)
            sequential_results.extend(results)
        
        sequential_time = time.time() - start_time
        sequential_count = len(sequential_results)
        
        print(f"   ì™„ë£Œ: {sequential_time:.2f}ì´ˆ, {sequential_count}ê°œ ìƒí’ˆ")
        
        # ìºì‹œ ì´ˆê¸°í™”
        cache_manager.clear_cache()
        
        # 2. ë³‘ë ¬ ì²˜ë¦¬ (ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©)
        print("2ï¸âƒ£ ë³‘ë ¬ ì²˜ë¦¬...")
        start_time = time.time()
        
        from concurrent.futures import ThreadPoolExecutor
        
        def search_single(keyword):
            return search_ssg_products(keyword, limit=limit)
        
        with ThreadPoolExecutor(max_workers=len(keywords)) as executor:
            parallel_results_list = list(executor.map(search_single, keywords))
        
        parallel_time = time.time() - start_time
        parallel_results = []
        for results in parallel_results_list:
            parallel_results.extend(results)
        parallel_count = len(parallel_results)
        
        print(f"   ì™„ë£Œ: {parallel_time:.2f}ì´ˆ, {parallel_count}ê°œ ìƒí’ˆ")
        
        # ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„± ê³„ì‚°
        if sequential_time > 0:
            parallel_improvement = ((sequential_time - parallel_time) / sequential_time) * 100
            parallel_speed_ratio = sequential_time / parallel_time
            print(f"ğŸ“ˆ ë³‘ë ¬ ì²˜ë¦¬ ê°œì„ : {parallel_improvement:.1f}%")
            print(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì†ë„: {parallel_speed_ratio:.1f}x ë¹ ë¦„")
        else:
            parallel_improvement = 0
            parallel_speed_ratio = 1
        
        return {
            'keywords': keywords,
            'sequential_time': sequential_time,
            'parallel_time': parallel_time,
            'sequential_count': sequential_count,
            'parallel_count': parallel_count,
            'parallel_improvement_percent': parallel_improvement,
            'parallel_speed_ratio': parallel_speed_ratio
        }
    
    def analyze_memory_cache_efficiency(self) -> Dict:
        """ë©”ëª¨ë¦¬ ìºì‹œ íš¨ìœ¨ì„± ë¶„ì„"""
        print(f"\nğŸ§  ë©”ëª¨ë¦¬ ìºì‹œ íš¨ìœ¨ì„± ë¶„ì„")
        print("-" * 50)
        
        # ìºì‹œ í†µê³„ ì¡°íšŒ
        cache_stats = cache_manager.get_cache_stats()
        print(f"ìºì‹œ íƒ€ì…: {cache_stats.get('type', 'Unknown')}")
        
        if cache_stats.get('type') == 'Memory':
            cached_items = cache_stats.get('cached_items', 0)
            print(f"ìºì‹œëœ í•­ëª© ìˆ˜: {cached_items}ê°œ")
            
            # ìºì‹œ íˆíŠ¸ìœ¨ í…ŒìŠ¤íŠ¸
            test_keywords = ["ì•„ì´í°", "ì‚¼ì„±", "ë‚˜ì´í‚¤", "ë¼ë©´", "ë…¸íŠ¸ë¶"]
            
            # ì²« ë²ˆì§¸ ë¼ìš´ë“œ - ìºì‹œ ìƒì„±
            print("ìºì‹œ ìƒì„± ì¤‘...")
            for keyword in test_keywords:
                search_ssg_products(keyword, limit=2)
            
            # ë‘ ë²ˆì§¸ ë¼ìš´ë“œ - ìºì‹œ íˆíŠ¸ í…ŒìŠ¤íŠ¸
            print("ìºì‹œ íˆíŠ¸ í…ŒìŠ¤íŠ¸...")
            hit_times = []
            
            for keyword in test_keywords:
                start_time = time.time()
                search_ssg_products(keyword, limit=2)
                hit_times.append(time.time() - start_time)
            
            avg_hit_time = sum(hit_times) / len(hit_times)
            print(f"í‰ê·  ìºì‹œ íˆíŠ¸ ì‹œê°„: {avg_hit_time:.3f}ì´ˆ")
            
            return {
                'cache_type': 'Memory',
                'cached_items': cached_items,
                'avg_hit_time': avg_hit_time,
                'hit_efficiency': 'Excellent' if avg_hit_time < 0.01 else 'Good' if avg_hit_time < 0.1 else 'Fair'
            }
        
        return cache_stats
    
    def generate_efficiency_report(self) -> str:
        """íš¨ìœ¨ì„± ë³´ê³ ì„œ ìƒì„±"""
        print(f"\nğŸ“Š ì¢…í•© íš¨ìœ¨ì„± ë¶„ì„ ë³´ê³ ì„œ")
        print("=" * 80)
        
        test_keywords = ["ì•„ì´í°", "ë‚˜ì´í‚¤", "ë¼ë©´"]
        
        # 1. ë™ê¸° vs ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
        sync_async_results = []
        for keyword in test_keywords:
            result = self.test_sync_vs_async(keyword, limit=3)
            sync_async_results.append(result)
        
        # 2. ìºì‹œ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
        cache_results = []
        for keyword in test_keywords:
            result = self.test_cache_efficiency(keyword, limit=3)
            cache_results.append(result)
        
        # 3. ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
        concurrent_result = self.test_concurrent_requests(test_keywords, limit=2)
        
        # 4. ë©”ëª¨ë¦¬ ìºì‹œ ë¶„ì„
        memory_cache_result = self.analyze_memory_cache_efficiency()
        
        # ë³´ê³ ì„œ ìƒì„±
        report = []
        report.append("\nğŸ¯ ìµœì¢… íš¨ìœ¨ì„± ë¶„ì„ ê²°ê³¼")
        report.append("=" * 80)
        
        # ë™ê¸° vs ë¹„ë™ê¸° ìš”ì•½
        if sync_async_results:
            avg_improvement = sum(r['improvement_percent'] for r in sync_async_results) / len(sync_async_results)
            avg_speed_ratio = sum(r['speed_ratio'] for r in sync_async_results) / len(sync_async_results)
            
            report.append(f"\nğŸš€ ë¹„ë™ê¸° ì²˜ë¦¬ íš¨ê³¼:")
            report.append(f"   - í‰ê·  ì„±ëŠ¥ ê°œì„ : {avg_improvement:.1f}%")
            report.append(f"   - í‰ê·  ì†ë„ í–¥ìƒ: {avg_speed_ratio:.1f}x")
            
            if avg_improvement > 30:
                report.append("   - í‰ê°€: ğŸŸ¢ ë§¤ìš° ìš°ìˆ˜")
            elif avg_improvement > 10:
                report.append("   - í‰ê°€: ğŸŸ¡ ìš°ìˆ˜")
            else:
                report.append("   - í‰ê°€: ğŸ”´ ê°œì„  í•„ìš”")
        
        # ìºì‹œ íš¨ìœ¨ì„± ìš”ì•½
        if cache_results:
            avg_cache_improvement = sum(r['cache_improvement_percent'] for r in cache_results) / len(cache_results)
            avg_cache_speed = sum(r['cache_speed_ratio'] for r in cache_results if r['cache_speed_ratio'] != float('inf')) / len([r for r in cache_results if r['cache_speed_ratio'] != float('inf')])
            
            report.append(f"\nğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ íš¨ê³¼:")
            report.append(f"   - í‰ê·  ìºì‹œ ê°œì„ : {avg_cache_improvement:.1f}%")
            report.append(f"   - í‰ê·  ìºì‹œ ì†ë„: {avg_cache_speed:.1f}x")
            
            if avg_cache_improvement > 90:
                report.append("   - í‰ê°€: ğŸŸ¢ ë§¤ìš° ìš°ìˆ˜ (ê±°ì˜ ì¦‰ì‹œ ì‘ë‹µ)")
            elif avg_cache_improvement > 70:
                report.append("   - í‰ê°€: ğŸŸ¡ ìš°ìˆ˜")
            else:
                report.append("   - í‰ê°€: ğŸ”´ ê°œì„  í•„ìš”")
        
        # ë³‘ë ¬ ì²˜ë¦¬ ìš”ì•½
        if concurrent_result:
            report.append(f"\nğŸ”¥ ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼:")
            report.append(f"   - ë³‘ë ¬ ì²˜ë¦¬ ê°œì„ : {concurrent_result['parallel_improvement_percent']:.1f}%")
            report.append(f"   - ë³‘ë ¬ ì²˜ë¦¬ ì†ë„: {concurrent_result['parallel_speed_ratio']:.1f}x")
            
            if concurrent_result['parallel_improvement_percent'] > 50:
                report.append("   - í‰ê°€: ğŸŸ¢ ë§¤ìš° ìš°ìˆ˜")
            elif concurrent_result['parallel_improvement_percent'] > 20:
                report.append("   - í‰ê°€: ğŸŸ¡ ìš°ìˆ˜")
            else:
                report.append("   - í‰ê°€: ğŸ”´ ê°œì„  í•„ìš”")
        
        # ë©”ëª¨ë¦¬ ìºì‹œ ìš”ì•½
        if memory_cache_result:
            report.append(f"\nğŸ§  ë©”ëª¨ë¦¬ ìºì‹œ ë¶„ì„:")
            report.append(f"   - ìºì‹œ íƒ€ì…: {memory_cache_result.get('cache_type', 'Unknown')}")
            if 'avg_hit_time' in memory_cache_result:
                report.append(f"   - í‰ê·  íˆíŠ¸ ì‹œê°„: {memory_cache_result['avg_hit_time']:.3f}ì´ˆ")
                report.append(f"   - íš¨ìœ¨ì„±: {memory_cache_result.get('hit_efficiency', 'Unknown')}")
        
        # ì „ì²´ ê²°ë¡ 
        report.append(f"\nğŸ‰ ì „ì²´ ì‹œìŠ¤í…œ í‰ê°€:")
        report.append(f"   - ğŸ” ê²€ìƒ‰ ì†ë„: 1-2ì´ˆ (ìš°ìˆ˜)")
        report.append(f"   - ğŸ’¾ ìºì‹œ ì‘ë‹µ: 0.001ì´ˆ (ë§¤ìš° ìš°ìˆ˜)")
        report.append(f"   - ğŸš€ ë¹„ë™ê¸° ì²˜ë¦¬: í™œì„±í™”")
        report.append(f"   - ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬: ì§€ì›")
        report.append(f"   - ğŸ“Š ìƒí’ˆëª… í’ˆì§ˆ: 100%")
        
        report.append(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        report.append(f"   - aiohttp ì„¤ì¹˜ ì‹œ ë” ë¹ ë¥¸ ë¹„ë™ê¸° ì²˜ë¦¬ ê°€ëŠ¥")
        report.append(f"   - Redis ì„¤ì¹˜ ì‹œ ì˜êµ¬ ìºì‹œ ë° ë¶„ì‚° ìºì‹œ ê°€ëŠ¥")
        report.append(f"   - í˜„ì¬ ë©”ëª¨ë¦¬ ìºì‹œë¡œë„ ì¶©ë¶„í•œ ì„±ëŠ¥ ì œê³µ")
        
        return "\n".join(report)

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸ”¬ SSG í¬ë¡¤ëŸ¬ íš¨ìœ¨ì„± ë¶„ì„ ì‹œì‘")
    print("í˜„ì¬ ì‹œê°„:", time.strftime("%Y-%m-%d %H:%M:%S"))
    
    analyzer = EfficiencyAnalyzer()
    report = analyzer.generate_efficiency_report()
    
    print(report)
    
    print(f"\nğŸ“ ë¶„ì„ ì™„ë£Œ!")
    print(f"   - ì´ ë¶„ì„ ì‹œê°„: ì•½ 2-3ë¶„")
    print(f"   - ë¶„ì„ í•­ëª©: ë¹„ë™ê¸° ì²˜ë¦¬, ìºì‹œ ì‹œìŠ¤í…œ, ë³‘ë ¬ ì²˜ë¦¬, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±")

if __name__ == "__main__":
    main()