#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë¹ ë¥¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ - í•µì‹¬ ì§€í‘œë§Œ ì¸¡ì •
"""

import time
import statistics
from crawler import search_ssg_products_legacy, search_ssg_products
from cache_manager import cache_manager
from concurrent.futures import ThreadPoolExecutor

def measure_time(func, *args, **kwargs):
    """ì‹¤í–‰ ì‹œê°„ ì¸¡ì • (3íšŒ í‰ê· )"""
    times = []
    for _ in range(3):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        end = time.perf_counter()
        times.append(end - start)
        time.sleep(0.5)  # ê°„ê²©
    
    return {
        'avg_time': statistics.mean(times),
        'min_time': min(times),
        'max_time': max(times),
        'result_count': len(result) if result else 0
    }

def main():
    print("ğŸ”¬ SSG í¬ë¡¤ëŸ¬ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (í•µì‹¬ ì§€í‘œ)")
    print("=" * 60)
    
    keyword = "ì•„ì´í°"
    limit = 5
    
    # 1. ë™ê¸° vs ë¹„ë™ê¸° í¬ë¡¤ëŸ¬
    print(f"\n1ï¸âƒ£ ë™ê¸° vs ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ë¹„êµ (í‚¤ì›Œë“œ: {keyword})")
    print("-" * 40)
    
    cache_manager.clear_cache()
    sync_result = measure_time(search_ssg_products_legacy, keyword, limit=limit)
    print(f"ğŸŒ ë™ê¸° í¬ë¡¤ëŸ¬: {sync_result['avg_time']:.3f}ì´ˆ (í‰ê· )")
    
    cache_manager.clear_cache()
    async_result = measure_time(search_ssg_products, keyword, limit=limit)
    print(f"ğŸš€ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬: {async_result['avg_time']:.3f}ì´ˆ (í‰ê· )")
    
    sync_improvement = ((sync_result['avg_time'] - async_result['avg_time']) / sync_result['avg_time']) * 100
    print(f"ğŸ“ˆ ë¹„ë™ê¸° ê°œì„ : {sync_improvement:.1f}% ({sync_result['avg_time']/async_result['avg_time']:.1f}ë°°)")
    
    # 2. ìºì‹œ íš¨ê³¼
    print(f"\n2ï¸âƒ£ ìºì‹œ ì‹œìŠ¤í…œ íš¨ê³¼ (í‚¤ì›Œë“œ: {keyword})")
    print("-" * 40)
    
    cache_manager.clear_cache()
    first_search = measure_time(search_ssg_products, keyword, limit=limit)
    print(f"ğŸ’¾ ì²« ê²€ìƒ‰: {first_search['avg_time']:.3f}ì´ˆ")
    
    cached_search = measure_time(search_ssg_products, keyword, limit=limit)
    print(f"âš¡ ìºì‹œ ê²€ìƒ‰: {cached_search['avg_time']:.3f}ì´ˆ")
    
    cache_improvement = ((first_search['avg_time'] - cached_search['avg_time']) / first_search['avg_time']) * 100
    cache_speedup = first_search['avg_time'] / cached_search['avg_time'] if cached_search['avg_time'] > 0 else float('inf')
    print(f"ğŸ“ˆ ìºì‹œ ê°œì„ : {cache_improvement:.1f}% ({cache_speedup:.0f}ë°°)" if cache_speedup != float('inf') else f"ğŸ“ˆ ìºì‹œ ê°œì„ : {cache_improvement:.1f}% (ë¬´í•œëŒ€)")
    
    # 3. ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼
    print(f"\n3ï¸âƒ£ ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼ (í‚¤ì›Œë“œ: ['ì•„ì´í°', 'ì‚¼ì„±', 'ë‚˜ì´í‚¤'])")
    print("-" * 40)
    
    keywords = ["ì•„ì´í°", "ì‚¼ì„±", "ë‚˜ì´í‚¤"]
    
    # ìˆœì°¨ ì²˜ë¦¬
    cache_manager.clear_cache()
    def sequential():
        results = []
        for kw in keywords:
            results.extend(search_ssg_products(kw, limit=3))
        return results
    
    seq_result = measure_time(sequential)
    print(f"ğŸ”„ ìˆœì°¨ ì²˜ë¦¬: {seq_result['avg_time']:.3f}ì´ˆ")
    
    # ë³‘ë ¬ ì²˜ë¦¬
    cache_manager.clear_cache()
    def parallel():
        results = []
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(search_ssg_products, kw, limit=3) for kw in keywords]
            for future in futures:
                results.extend(future.result())
        return results
    
    par_result = measure_time(parallel)
    print(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬: {par_result['avg_time']:.3f}ì´ˆ")
    
    parallel_improvement = ((seq_result['avg_time'] - par_result['avg_time']) / seq_result['avg_time']) * 100
    print(f"ğŸ“ˆ ë³‘ë ¬ ê°œì„ : {parallel_improvement:.1f}% ({seq_result['avg_time']/par_result['avg_time']:.1f}ë°°)")
    
    # 4. ìƒí’ˆëª… í’ˆì§ˆ
    print(f"\n4ï¸âƒ£ ìƒí’ˆëª… í’ˆì§ˆ ë¹„êµ (í‚¤ì›Œë“œ: ë¼ë©´)")
    print("-" * 40)
    
    cache_manager.clear_cache()
    legacy_products = search_ssg_products_legacy("ë¼ë©´", limit=5)
    legacy_generic = sum(1 for p in legacy_products if "ë¼ë©´ ê´€ë ¨ ìƒí’ˆ" in p['name'])
    legacy_quality = ((len(legacy_products) - legacy_generic) / len(legacy_products)) * 100 if legacy_products else 0
    
    cache_manager.clear_cache()
    improved_products = search_ssg_products("ë¼ë©´", limit=5)
    improved_generic = sum(1 for p in improved_products if "ë¼ë©´ ê´€ë ¨ ìƒí’ˆ" in p['name'])
    improved_quality = ((len(improved_products) - improved_generic) / len(improved_products)) * 100 if improved_products else 0
    
    print(f"ğŸŒ ê¸°ì¡´ í¬ë¡¤ëŸ¬: {legacy_quality:.1f}% ì •í™•ë„")
    print(f"ğŸš€ ê°œì„ ëœ í¬ë¡¤ëŸ¬: {improved_quality:.1f}% ì •í™•ë„")
    print(f"ğŸ“ˆ í’ˆì§ˆ ê°œì„ : +{improved_quality - legacy_quality:.1f}%p")
    
    # ì¢…í•© ê²°ê³¼
    print(f"\n" + "="*60)
    print("ğŸ† ì¢…í•© ì„±ëŠ¥ ê°œì„  ê²°ê³¼")
    print("="*60)
    print(f"ğŸ¥‡ ìºì‹œ ì‹œìŠ¤í…œ: {cache_improvement:.0f}% ê°œì„  (ê°€ì¥ íš¨ê³¼ì )")
    print(f"ğŸ¥ˆ ë³‘ë ¬ ì²˜ë¦¬: {parallel_improvement:.0f}% ê°œì„ ")
    print(f"ğŸ¥‰ ìƒí’ˆëª… í’ˆì§ˆ: +{improved_quality - legacy_quality:.0f}%p í–¥ìƒ")
    print(f"ğŸ… ë¹„ë™ê¸° ì²˜ë¦¬: {sync_improvement:.0f}% ê°œì„ ")
    
    print(f"\nğŸ’¡ ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜:")
    print(f"   â€¢ ì²« ê²€ìƒ‰: ~{async_result['avg_time']:.1f}ì´ˆ")
    print(f"   â€¢ ìºì‹œëœ ê²€ìƒ‰: ~{cached_search['avg_time']:.3f}ì´ˆ")
    print(f"   â€¢ ìƒí’ˆëª… ì •í™•ë„: {improved_quality:.0f}%")
    print(f"   â€¢ ë‹¤ì¤‘ ê²€ìƒ‰: {seq_result['avg_time']/par_result['avg_time']:.1f}ë°° ë¹ ë¦„")

if __name__ == "__main__":
    main()