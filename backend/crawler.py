import requests
from bs4 import BeautifulSoup
import re
import time
import json
from urllib.parse import quote

# ìƒˆë¡œìš´ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ import
try:
    from async_crawler import search_ssg_products_enhanced
    ASYNC_AVAILABLE = True
    print("âœ… ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    ASYNC_AVAILABLE = False

def get_headers():
    """ê³µí†µ í—¤ë” ë°˜í™˜"""
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }

def search_ssg_products_legacy(keyword, page=1, limit=20):
    """SSGì—ì„œ ìƒí’ˆ ê²€ìƒ‰ (ìµœì í™”ëœ ê³ ì† ë²„ì „)"""
    try:
        encoded_keyword = quote(keyword)
        search_url = f"https://www.ssg.com/search.ssg?target=all&query={encoded_keyword}&page={page}"
        
        headers = get_headers()
        response = requests.get(search_url, headers=headers, timeout=5)  # íƒ€ì„ì•„ì›ƒ ë” ë‹¨ì¶•
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        products = []
        
        # ìƒí’ˆ ë§í¬ ì°¾ê¸° ìµœì í™” - ë” êµ¬ì²´ì ì¸ ì„ íƒì ì‚¬ìš©
        product_links = soup.select('a[href*="itemView.ssg"][href*="itemId="]')
        
        # ê´‘ê³  ë§í¬ ì œì™¸ (ê°•í™”ëœ ë²„ì „)
        filtered_links = []
        for link in product_links[:limit * 5]:  # ë” ë§ì€ ë§í¬ í™•ì¸
            href = link.get('href', '')
            link_text = link.get_text(strip=True)
            
            # ê´‘ê³  ë§í¬ ì œì™¸ ì¡°ê±´ ê°•í™”
            if ('advertBidId' not in href and 
                'ADAD' not in link_text and
                'advertExtensTeryDivCd' not in href):
                filtered_links.append(link)
                if len(filtered_links) >= limit * 2:  # í•„ìš”í•œ ë§Œí¼ë§Œ ìˆ˜ì§‘
                    break
        
        print(f"ìœ íš¨í•œ ìƒí’ˆ ë§í¬ {len(filtered_links)}ê°œ ë°œê²¬")
        
        # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (ë” ë¹ ë¥¸ ì²˜ë¦¬)
        processed_urls = set()
        
        for link in filtered_links:
            if len(products) >= limit:
                break
                
            try:
                href = link.get('href')
                if href.startswith('/'):
                    product_url = f"https://www.ssg.com{href}"
                else:
                    product_url = href
                
                # ì¤‘ë³µ ì œê±°
                if product_url in processed_urls:
                    continue
                processed_urls.add(product_url)
                
                # ìƒí’ˆëª… ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë¡œì§)
                name = extract_product_name_fast(link, keyword)
                
                # ê°€ê²© ì¶”ì¶œ (ê°„ì†Œí™”) - ìµœëŒ€ 3ë‹¨ê³„ë§Œ í™•ì¸
                price = 0
                current = link.parent
                for _ in range(3):  # ë‹¨ê³„ ì¶•ì†Œ
                    if current:
                        price_text = current.get_text()
                        price = extract_price_fast(price_text)
                        if price > 0:
                            break
                        current = current.parent
                    else:
                        break
                
                # ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ (ê°„ì†Œí™”)
                brand = extract_brand_fast(link, name)
                
                # ì´ë¯¸ì§€ ì°¾ê¸° (ê°„ì†Œí™”) - ìµœëŒ€ 2ë‹¨ê³„ë§Œ í™•ì¸
                image_url = None
                current = link.parent
                for _ in range(2):  # ë‹¨ê³„ ì¶•ì†Œ
                    if current:
                        img = current.find('img')
                        if img:
                            image_url = img.get('src') or img.get('data-src')
                            if image_url:
                                if image_url.startswith('//'):
                                    image_url = f"https:{image_url}"
                                elif image_url.startswith('/'):
                                    image_url = f"https://www.ssg.com{image_url}"
                                break
                        current = current.parent
                    else:
                        break
                
                # ìƒí’ˆ ì •ë³´ ì¶”ê°€
                products.append({
                    'name': name.strip(),
                    'price': price,
                    'url': product_url,
                    'image_url': image_url,
                    'brand': brand,
                    'source': 'SSG'
                })
                
            except Exception as e:
                continue  # ì˜¤ë¥˜ ì¶œë ¥ ì œê±°ë¡œ ì†ë„ í–¥ìƒ
        
        print(f"ìµœì¢… ì¶”ì¶œëœ ìƒí’ˆ: {len(products)}ê°œ")
        
        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ìƒì„±
        if not products:
            print("ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            products = create_dummy_products(keyword, limit)
        
        return products[:limit]
        
    except Exception as e:
        print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return create_dummy_products(keyword, limit)

def create_dummy_products(keyword, limit=5):
    """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ìƒí’ˆ ë°ì´í„° ìƒì„±"""
    import random
    
    dummy_products = []
    base_prices = [29900, 49900, 79900, 99900, 149900, 199900, 299900]
    
    for i in range(min(limit, 5)):
        price = random.choice(base_prices) + random.randint(-10000, 10000)
        dummy_products.append({
            'name': f"{keyword} ê´€ë ¨ ìƒí’ˆ {i+1} - í…ŒìŠ¤íŠ¸ ë°ì´í„°",
            'price': max(price, 10000),
            'url': f"https://www.ssg.com/item/itemView.ssg?itemId=test{i+1}",
            'image_url': f"https://via.placeholder.com/200x200?text={keyword}+{i+1}",
            'brand': f"í…ŒìŠ¤íŠ¸ ë¸Œëœë“œ {i+1}",
            'source': 'SSG'
        })
    
    return dummy_products

def crawl_ssg_product(url):
    """SSG ìƒí’ˆ ì •ë³´ í¬ë¡¤ë§ (ê¸°ì¡´ í•¨ìˆ˜ ê°œì„ )"""
    try:
        headers = get_headers()
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ìƒí’ˆëª… ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        name_selectors = [
            'h2.cdtl_prd_nm',
            'h1.cdtl_prd_nm',
            '.prod_tit',
            '.item_tit',
            'title'
        ]
        
        name = None
        for selector in name_selectors:
            name_element = soup.select_one(selector)
            if name_element:
                name = name_element.get_text(strip=True)
                if name and name != "SSG.COM":
                    break
        
        if not name:
            name = "ìƒí’ˆëª… ì—†ìŒ"
        
        # ê°€ê²© ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        price_selectors = [
            '.cdtl_old_price .blind',
            '.cdtl_price .blind',
            '.price_original',
            '.price_discount',
            '.ssg_price',
            '.price'
        ]
        
        price = 0
        for selector in price_selectors:
            price_element = soup.select_one(selector)
            if price_element:
                price_text = price_element.get_text(strip=True)
                price_match = re.search(r'(\d{1,3}(?:,\d{3})*)', price_text.replace(',', ''))
                if price_match:
                    price = int(price_match.group(1).replace(',', ''))
                    break
        
        # ì´ë¯¸ì§€ URL ì¶”ì¶œ
        image_url = None
        img_selectors = [
            '.cdtl_img_wrap img',
            '.prod_img img',
            '.item_img img'
        ]
        
        for selector in img_selectors:
            img_element = soup.select_one(selector)
            if img_element:
                image_url = img_element.get('src') or img_element.get('data-src')
                if image_url and image_url.startswith('//'):
                    image_url = f"https:{image_url}"
                break
        
        return {
            'name': name,
            'price': price,
            'url': url,
            'image_url': image_url
        }
        
    except Exception as e:
        print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None

def compare_products(keyword, limit=10):
    """ìƒí’ˆ ê²€ìƒ‰ ë° ê°€ê²© ë¹„êµ"""
    try:
        products = search_ssg_products(keyword, limit=limit)
        
        if not products:
            return []
        
        # ê°€ê²©ìˆœ ì •ë ¬
        products_sorted = sorted(products, key=lambda x: x['price'] if x['price'] > 0 else float('inf'))
        
        # ê°€ê²© ë¹„êµ ì •ë³´ ì¶”ê°€
        for i, product in enumerate(products_sorted):
            if i == 0 and product['price'] > 0:
                product['price_rank'] = 'ìµœì €ê°€'
                product['price_diff'] = 0
            elif product['price'] > 0:
                lowest_price = products_sorted[0]['price']
                product['price_diff'] = product['price'] - lowest_price
                product['price_rank'] = f"{i+1}ìœ„"
            else:
                product['price_rank'] = 'ê°€ê²© ì •ë³´ ì—†ìŒ'
                product['price_diff'] = 0
        
        return products_sorted
        
    except Exception as e:
        print(f"ìƒí’ˆ ë¹„êµ ì˜¤ë¥˜: {e}")
        return []

def extract_product_name_from_ssg(link, product_url, keyword):
    """SSGì—ì„œ ì •í™•í•œ ìƒí’ˆëª… ì¶”ì¶œ"""
    try:
        # 1. ë§í¬ í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ
        name = link.get_text(strip=True)
        
        # 2. ë§í¬ í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ë©´ ì£¼ë³€ ìš”ì†Œì—ì„œ ì°¾ê¸°
        if not name or len(name) < 10:
            current = link.parent
            for level in range(7):  # ë” ë§ì€ ë ˆë²¨ í™•ì¸
                if current:
                    # ìƒí’ˆëª… ê´€ë ¨ í´ë˜ìŠ¤ ì°¾ê¸°
                    name_selectors = [
                        '.item_tit', '.prod_tit', '.product_title', '.title',
                        '.item_name', '.prod_name', '.product_name', '.name',
                        '.goods_name', '.goods_title', '.item_info_tit'
                    ]
                    
                    for selector in name_selectors:
                        name_elem = current.select_one(selector)
                        if name_elem:
                            candidate_name = name_elem.get_text(strip=True)
                            if candidate_name and len(candidate_name) > 10:
                                name = candidate_name
                                break
                    
                    if name and len(name) > 10:
                        break
                    
                    # í´ë˜ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ í…ìŠ¤íŠ¸ íŒ¨í„´ìœ¼ë¡œ ì°¾ê¸°
                    current_text = current.get_text(strip=True)
                    if current_text and 15 < len(current_text) < 300:
                        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                        clean_text = re.sub(r'(ë¦¬ë·°|ë³„ì |ê°¯ìˆ˜|í• ì¸ìœ¨|ì •ìƒê°€ê²©|íŒë§¤ê°€ê²©|ë°°ì†¡|ë¬´ë£Œë°°ì†¡|ë‹¹ì¼ë°°ì†¡).*', '', current_text)
                        clean_text = re.sub(r'(\d{1,3}(?:,\d{3})*ì›).*', '', clean_text)  # ê°€ê²© ì´í›„ í…ìŠ¤íŠ¸ ì œê±°
                        
                        if len(clean_text) > 15:
                            name = clean_text[:150]
                            break
                    
                    current = current.parent
                else:
                    break
        
        # 3. ê°œë³„ í˜ì´ì§€ ì ‘ê·¼ì€ ì œê±° (ì†ë„ ê°œì„ ì„ ìœ„í•´)
        
        # 4. ìƒí’ˆëª… ì •ì œ
        if name:
            # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            name = re.sub(r'(ë¦¬ë·°\s*\d+|ë³„ì \s*[\d.]+|ê°¯ìˆ˜\s*\d+)', '', name)
            name = re.sub(r'(í• ì¸ìœ¨\s*\d+%|ì •ìƒê°€ê²©|íŒë§¤ê°€ê²©)', '', name)
            name = re.sub(r'(ë°°ì†¡|ë¬´ë£Œë°°ì†¡|ë‹¹ì¼ë°°ì†¡|íƒë°°)', '', name)
            name = re.sub(r'(ì¹´ë“œí• ì¸|ì¦‰ì‹œí• ì¸|ì¶”ê°€í• ì¸)', '', name)
            name = re.sub(r'(ì‚¬ì€í’ˆ|ì¦ì •|ì´ë²¤íŠ¸)', '', name)
            name = re.sub(r'\s+', ' ', name).strip()  # ì—°ì† ê³µë°± ì œê±°
            
            # ìƒí’ˆëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(name) > 100:
                name = name[:100] + "..."
            
            return name
        
        # 5. ìµœí›„ ìˆ˜ë‹¨: ê¸°ë³¸ê°’ ë°˜í™˜
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"
        
    except Exception as e:
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"

def get_product_name_from_ssg_page(product_url):
    """SSG ê°œë³„ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ"""
    try:
        headers = get_headers()
        response = requests.get(product_url, headers=headers, timeout=8)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # SSG ìƒí’ˆ í˜ì´ì§€ì˜ ìƒí’ˆëª… ì„ íƒìë“¤
        name_selectors = [
            'h2.cdtl_prd_nm',
            'h1.cdtl_prd_nm', 
            '.prod_tit',
            '.item_tit',
            '.product_title',
            '.goods_name',
            'title'
        ]
        
        for selector in name_selectors:
            name_elem = soup.select_one(selector)
            if name_elem:
                name = name_elem.get_text(strip=True)
                if name and name != "SSG.COM" and len(name) > 10:
                    return name
        
        return None
        
    except Exception as e:
        return None

def extract_brand_from_ssg(link, product_name):
    """SSGì—ì„œ ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # 1. ë§í¬ ì£¼ë³€ ìš”ì†Œì—ì„œ ë¸Œëœë“œ ì •ë³´ ì°¾ê¸°
        current = link.parent
        for _ in range(5):  # ìµœëŒ€ 5ë‹¨ê³„ ë¶€ëª¨ê¹Œì§€ í™•ì¸
            if current:
                # ë¸Œëœë“œ ê´€ë ¨ í´ë˜ìŠ¤ë‚˜ ì†ì„± ì°¾ê¸°
                brand_selectors = [
                    '.brand', '.brand_name', '.brand_info', '.brand_txt',
                    '.maker', '.maker_name', '.company', '.company_name',
                    '.vendor', '.vendor_name', '.seller', '.seller_name'
                ]
                
                for selector in brand_selectors:
                    brand_elem = current.select_one(selector)
                    if brand_elem:
                        brand_text = brand_elem.get_text(strip=True)
                        if brand_text and len(brand_text) < 50:  # ë¸Œëœë“œëª…ì€ ë³´í†µ ì§§ìŒ
                            return brand_text
                
                # í…ìŠ¤íŠ¸ì—ì„œ ë¸Œëœë“œ íŒ¨í„´ ì°¾ê¸°
                current_text = current.get_text()
                brand_match = re.search(r'ë¸Œëœë“œ[:\s]*([ê°€-í£A-Za-z0-9\s&]+)', current_text)
                if brand_match:
                    brand = brand_match.group(1).strip()
                    if len(brand) < 30:
                        return brand
                
                current = current.parent
            else:
                break
        
        # 2. ìƒí’ˆëª…ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
        if product_name:
            # ì˜ ì•Œë ¤ì§„ ë¸Œëœë“œ íŒ¨í„´
            known_brands = [
                # ì „ìì œí’ˆ
                'APPLE', 'ì‚¼ì„±', 'SAMSUNG', 'LG', 'ì†Œë‹ˆ', 'SONY', 'í™”ì›¨ì´', 'HUAWEI',
                'ìƒ¤ì˜¤ë¯¸', 'XIAOMI', 'êµ¬ê¸€', 'GOOGLE', 'ë§ˆì´í¬ë¡œì†Œí”„íŠ¸', 'MICROSOFT',
                # íŒ¨ì…˜
                'ë‚˜ì´í‚¤', 'NIKE', 'ì•„ë””ë‹¤ìŠ¤', 'ADIDAS', 'í‘¸ë§ˆ', 'PUMA', 'ì–¸ë”ì•„ë¨¸', 'UNDER ARMOUR',
                'ìœ ë‹ˆí´ë¡œ', 'UNIQLO', 'ìë¼', 'ZARA', 'H&M',
                # ì‹í’ˆ
                'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'íŒ”ë„', 'ë¡¯ë°', 'LOTTE', 'CJ', 'ë™ì›',
                # í™”ì¥í’ˆ
                'ì•„ëª¨ë ˆí¼ì‹œí”½', 'ë”í˜ì´ìŠ¤ìƒµ', 'ì´ë‹ˆìŠ¤í”„ë¦¬', 'ì—ë›°ë“œ', 'ë¯¸ìƒ¤', 'MISSHA',
                # ìƒí™œìš©í’ˆ
                'P&G', 'ìœ í•œí‚´ë²Œë¦¬', 'ì• ê²½', 'ë¼ì´ì˜¨', 'LION'
            ]
            
            product_upper = product_name.upper()
            for brand in known_brands:
                if brand.upper() in product_upper:
                    return brand
            
            # ìƒí’ˆëª… ì²« ë‹¨ì–´ê°€ ë¸Œëœë“œì¼ ê°€ëŠ¥ì„±
            first_word = product_name.split()[0] if product_name.split() else ''
            if first_word and len(first_word) > 1 and len(first_word) < 20:
                # ì˜ë¬¸ì´ë‚˜ í•œê¸€ë¡œë§Œ êµ¬ì„±ëœ ê²½ìš°
                if re.match(r'^[A-Za-zê°€-í£]+$', first_word):
                    return first_word
        
        # 3. ê¸°ë³¸ê°’ ë°˜í™˜
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'
        
    except Exception as e:
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'

def extract_price_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ê°€ê²© ì¶”ì¶œ"""
    if not text:
        return 0
    
    # ì—¬ëŸ¬ ê°€ê²© íŒ¨í„´ ì‹œë„
    patterns = [
        r'íŒë§¤ê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
        r'ì •ìƒê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
        r'(\d{1,3}(?:,\d{3})*)\s*ì›',
        r'ê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
        r'(\d{1,3}(?:,\d{3})*)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        if matches:
            # ê°€ì¥ í° ìˆ«ìë¥¼ ê°€ê²©ìœ¼ë¡œ ê°„ì£¼ (í• ì¸ê°€ë³´ë‹¤ ì •ê°€ê°€ í´ ìˆ˜ ìˆìŒ)
            prices = [int(match.replace(',', '')) for match in matches]
            valid_prices = [p for p in prices if 1000 <= p <= 10000000]  # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„
            if valid_prices:
                return min(valid_prices)  # ìµœì €ê°€ ë°˜í™˜
    
    return 0

def get_product_price_from_page(url):
    """ê°œë³„ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ê°€ê²© ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        headers = get_headers()
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê°€ê²© ì„ íƒìë“¤
        price_selectors = [
            '.cdtl_old_price .blind',
            '.cdtl_price .blind', 
            '.price_original',
            '.price_discount',
            '.ssg_price',
            '.price'
        ]
        
        for selector in price_selectors:
            price_elem = soup.select_one(selector)
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                price = extract_price_from_text(price_text)
                if price > 0:
                    return price
        
        # ì „ì²´ í˜ì´ì§€ì—ì„œ ê°€ê²© íŒ¨í„´ ì°¾ê¸°
        page_text = soup.get_text()
        price = extract_price_from_text(page_text)
        return price
        
    except Exception as e:
        print(f"ê°œë³„ í˜ì´ì§€ ê°€ê²© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return 0

def test_search():
    """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    keyword = "ì•„ì´í°"
    print(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼:")
    products = search_ssg_products(keyword, limit=3)
    
    for i, product in enumerate(products, 1):
        print(f"{i}. {product['name'][:50]}...")
        
        # ê°€ê²©ì´ 0ì´ë©´ ê°œë³„ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        if product['price'] == 0 and product['url'] and 'itemView.ssg' in product['url']:
            print(f"   ê°œë³„ í˜ì´ì§€ì—ì„œ ê°€ê²© í™•ì¸ ì¤‘...")
            product['price'] = get_product_price_from_page(product['url'])
        
        print(f"   ê°€ê²©: {product['price']:,}ì›")
        print(f"   ë¸Œëœë“œ: {product['brand']}")
        print(f"   URL: {product['url']}")
        print()

def test_compare():
    """ê°€ê²© ë¹„êµ í…ŒìŠ¤íŠ¸"""
    keyword = "ë¬´ì„ ì´ì–´í°"
    print(f"'{keyword}' ê°€ê²© ë¹„êµ:")
    products = compare_products(keyword, limit=3)
    
    for product in products:
        print(f"[{product['price_rank']}] {product['name'][:50]}...")
        print(f"ê°€ê²©: {product['price']:,}ì› (+{product['price_diff']:,}ì›)")
        print(f"ë¸Œëœë“œ: {product['brand']}")
        print()

def test_single_product():
    """ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
    test_url = "https://www.ssg.com/item/itemView.ssg?itemId=1000618003010"
    print(f"ë‹¨ì¼ ìƒí’ˆ í…ŒìŠ¤íŠ¸: {test_url}")
    result = crawl_ssg_product(test_url)
    if result:
        print(f"ìƒí’ˆëª…: {result['name']}")
        print(f"ê°€ê²©: {result['price']:,}ì›")
        print(f"ì´ë¯¸ì§€: {result['image_url']}")
    else:
        print("í¬ë¡¤ë§ ì‹¤íŒ¨")

def extract_product_name_fast(link, keyword):
    """ë¹ ë¥¸ ìƒí’ˆëª… ì¶”ì¶œ (ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼ë²•)"""
    try:
        # 1. ë§í¬ì™€ ì£¼ë³€ ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_texts = []
        
        # ë§í¬ ìì²´ í…ìŠ¤íŠ¸
        link_text = link.get_text(strip=True)
        if link_text:
            all_texts.append(link_text)
        
        # ë¶€ëª¨ ìš”ì†Œë“¤ì˜ í…ìŠ¤íŠ¸ (ë” ê´‘ë²”ìœ„í•˜ê²Œ)
        current = link.parent
        for level in range(8):  # ë” ë§ì€ ë ˆë²¨ í™•ì¸
            if current:
                # ëª¨ë“  ìì‹ í…ìŠ¤íŠ¸ ë…¸ë“œ ìˆ˜ì§‘
                text_nodes = current.find_all(text=True)
                for text_node in text_nodes:
                    text = text_node.strip()
                    if text and len(text) > 5:
                        all_texts.append(text)
                
                # íŠ¹ì • íƒœê·¸ë“¤ì˜ í…ìŠ¤íŠ¸ë„ ìˆ˜ì§‘
                for tag in ['span', 'div', 'p', 'h1', 'h2', 'h3', 'strong', 'em']:
                    elements = current.find_all(tag)
                    for elem in elements[:10]:  # ê° íƒœê·¸ë‹¹ ìµœëŒ€ 10ê°œ
                        elem_text = elem.get_text(strip=True)
                        if elem_text and len(elem_text) > 5:
                            all_texts.append(elem_text)
                
                current = current.parent
            else:
                break
        
        # 2. ìˆ˜ì§‘ëœ í…ìŠ¤íŠ¸ë“¤ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ìƒí’ˆëª… ì°¾ê¸°
        best_candidates = []
        
        for text in all_texts:
            if not text or len(text) < 10:
                continue
            
            # í…ìŠ¤íŠ¸ ì •ì œ
            cleaned_text = clean_text_line(text)
            if not cleaned_text or len(cleaned_text) < 10:
                continue
            
            # ìƒí’ˆëª… ì ìˆ˜ ê³„ì‚°
            score = calculate_product_name_score(cleaned_text, keyword)
            if score > 0:
                best_candidates.append((cleaned_text, score))
        
        # 3. ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìƒí’ˆëª… ì„ íƒ
        if best_candidates:
            best_candidates.sort(key=lambda x: x[1], reverse=True)
            best_name = best_candidates[0][0]
            return clean_product_name(best_name[:120])
        
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"
        
    except Exception:
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"

def calculate_product_name_score(text, keyword):
    """ìƒí’ˆëª… ì í•©ì„± ì ìˆ˜ ê³„ì‚°"""
    if not text or is_generic_text(text):
        return 0
    
    score = 0
    text_lower = text.lower()
    keyword_lower = keyword.lower()
    
    # ê¸°ë³¸ ì ìˆ˜
    score += 10
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ë†’ì€ ì ìˆ˜
    if keyword_lower in text_lower:
        score += 50
    
    # ë¸Œëœë“œëª… í¬í•¨ ì‹œ ì ìˆ˜ ì¶”ê°€
    brands = [
        'apple', 'ì‚¼ì„±', 'samsung', 'lg', 'ë‚˜ì´í‚¤', 'nike', 'adidas', 
        'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'íŒ”ë„', 'ë¡¯ë°', 'lotte', 'cj',
        'ì•„ëª¨ë ˆ', 'ì´ë‹ˆìŠ¤í”„ë¦¬', 'ì—ë›°ë“œ', 'ë¯¸ìƒ¤', 'ë”í˜ì´ìŠ¤ìƒµ',
        'ì§€ì˜¤ë‹¤ë…¸', 'ìœ ë‹ˆí´ë¡œ', 'uniqlo', 'ìë¼', 'zara'
    ]
    
    for brand in brands:
        if brand in text_lower:
            score += 30
            break
    
    # ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì ìˆ˜ ì¶”ê°€
    product_keywords = [
        'gb', 'í”„ë¡œ', 'ë§¥ìŠ¤', 'ë¯¸ë‹ˆ', 'í”ŒëŸ¬ìŠ¤', 'ìš¸íŠ¸ë¼', 'ì—ì–´',
        'í‹°ì…”ì¸ ', 'í›„ë“œ', 'ë°”ì§€', 'ì›í”¼ìŠ¤', 'ìŠ¤ì»¤íŠ¸', 'ìì¼“',
        'ìŠ¤ë‹ˆì»¤ì¦ˆ', 'ë¶€ì¸ ', 'ìƒŒë“¤', 'ìŠ¬ë¦¬í¼',
        'í¬ë¦¼', 'ë¡œì…˜', 'ì„¸ëŸ¼', 'ë§ˆìŠ¤í¬', 'í´ë Œì €',
        'ë…¸íŠ¸ë¶', 'íƒœë¸”ë¦¿', 'ìŠ¤ë§ˆíŠ¸í°', 'ì´ì–´í°', 'ì¼€ì´ìŠ¤'
    ]
    
    for keyword in product_keywords:
        if keyword in text_lower:
            score += 20
            break
    
    # ëª¨ë¸ëª…ì´ë‚˜ ì œí’ˆ ì½”ë“œ í¬í•¨ ì‹œ ì ìˆ˜ ì¶”ê°€
    if re.search(r'[A-Z0-9]{3,}', text):
        score += 15
    
    # ê°€ê²©ì´ë‚˜ ë¦¬ë·° ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš° ì ìˆ˜ ê°ì†Œ
    if any(word in text_lower for word in ['ì›', 'ë¦¬ë·°', 'ë³„ì ', 'í• ì¸', 'ë°°ì†¡']):
        score -= 20
    
    # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ í…ìŠ¤íŠ¸ ì ìˆ˜ ê°ì†Œ
    if len(text) < 15 or len(text) > 150:
        score -= 10
    
    return max(0, score)

def clean_text_line(text):
    """í…ìŠ¤íŠ¸ ë¼ì¸ ì •ì œ (ê°œì„ ëœ ë²„ì „)"""
    if not text:
        return ""
    
    # íŒë§¤ê°€ê²© ì´ì „ê¹Œì§€ë§Œ ì¶”ì¶œ (ìƒí’ˆëª… ë¶€ë¶„)
    text = re.sub(r'íŒë§¤ê°€ê²©.*', '', text)
    # ê°€ê²© ì´í›„ í…ìŠ¤íŠ¸ ì œê±°
    text = re.sub(r'(\d{1,3}(?:,\d{3})*ì›).*', '', text)
    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    text = re.sub(r'(ë¦¬ë·°|ë³„ì |í• ì¸|ë°°ì†¡|ë¬´ë£Œë°°ì†¡|ë‹¹ì¼ë°°ì†¡|íƒë°°).*', '', text)
    text = re.sub(r'(ì¹´ë“œí• ì¸|ì¦‰ì‹œí• ì¸|ì¶”ê°€í• ì¸|ì‚¬ì€í’ˆ|ì¦ì •).*', '', text)
    text = re.sub(r'(100gë‹¹|ê°œë‹¹|mlë‹¹).*', '', text)  # ë‹¨ìœ„ë‹¹ ê°€ê²© ì œê±°
    # ì—°ì† ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def is_generic_text(text):
    """ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
    if not text:
        return True
    
    generic_patterns = [
        r'^(ìƒí’ˆ|ì œí’ˆ|ì•„ì´í…œ)$',
        r'^(ì´ë¯¸ì§€|ì‚¬ì§„|ê·¸ë¦¼)$',
        r'^(ë§í¬|ë°”ë¡œê°€ê¸°)$',
        r'^(ë”ë³´ê¸°|ìì„¸íˆ)$',
        r'^\d+$',  # ìˆ«ìë§Œ
        r'^[ê°€-í£]{1,2}$',  # í•œê¸€ 1-2ì
    ]
    
    for pattern in generic_patterns:
        if re.match(pattern, text.strip()):
            return True
    
    return False

def has_product_keywords(text, keyword):
    """ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    if not text:
        return False
    
    text_lower = text.lower()
    keyword_lower = keyword.lower()
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    if keyword_lower in text_lower:
        return True
    
    # ë¸Œëœë“œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    brand_keywords = [
        'apple', 'ì‚¼ì„±', 'samsung', 'lg', 'ë‚˜ì´í‚¤', 'nike', 'adidas',
        'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'íŒ”ë„', 'ë¡¯ë°', 'lotte'
    ]
    
    for brand in brand_keywords:
        if brand in text_lower:
            return True
    
    # ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    product_keywords = ['gb', 'í”„ë¡œ', 'ë§¥ìŠ¤', 'ë¯¸ë‹ˆ', 'í”ŒëŸ¬ìŠ¤', 'ìš¸íŠ¸ë¼']
    for prod_keyword in product_keywords:
        if prod_keyword in text_lower:
            return True
    
    return False

def extract_price_fast(text):
    """ë¹ ë¥¸ ê°€ê²© ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    if not text:
        return 0
    
    # ê°€ì¥ ê°„ë‹¨í•œ ê°€ê²© íŒ¨í„´ë§Œ ì‚¬ìš©
    price_match = re.search(r'(\d{1,3}(?:,\d{3})*)\s*ì›', text)
    if price_match:
        try:
            price = int(price_match.group(1).replace(',', ''))
            if 100 <= price <= 10000000:
                return price
        except:
            pass
    
    return 0

def extract_brand_fast(link, product_name):
    """ë¹ ë¥¸ ë¸Œëœë“œ ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    try:
        if product_name:
            # ì˜ ì•Œë ¤ì§„ ë¸Œëœë“œë§Œ ë¹ ë¥´ê²Œ í™•ì¸
            known_brands = [
                'APPLE', 'ì‚¼ì„±', 'SAMSUNG', 'LG', 'ë‚˜ì´í‚¤', 'NIKE', 
                'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'ì•„ë””ë‹¤ìŠ¤', 'ADIDAS'
            ]
            
            product_upper = product_name.upper()
            for brand in known_brands:
                if brand.upper() in product_upper:
                    return brand
            
            # ì²« ë‹¨ì–´ë§Œ í™•ì¸
            first_word = product_name.split()[0] if product_name.split() else ''
            if first_word and 2 < len(first_word) < 15:
                return first_word
        
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'
        
    except Exception:
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'

def get_product_name_from_page_fast(product_url):
    """ê°œë³„ í˜ì´ì§€ì—ì„œ ë¹ ë¥¸ ìƒí’ˆëª… ì¶”ì¶œ"""
    try:
        headers = get_headers()
        response = requests.get(product_url, headers=headers, timeout=3)  # ë§¤ìš° ì§§ì€ íƒ€ì„ì•„ì›ƒ
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê°€ì¥ í™•ì‹¤í•œ ì„ íƒìë“¤ë§Œ ì‚¬ìš©
        name_selectors = [
            'h2.cdtl_prd_nm',
            'h1.cdtl_prd_nm',
            '.prod_tit',
            '.item_tit'
        ]
        
        for selector in name_selectors:
            name_elem = soup.select_one(selector)
            if name_elem:
                name = name_elem.get_text(strip=True)
                if name and name != "SSG.COM" and len(name) > 10:
                    return name
        
        return None
        
    except Exception:
        return None

def clean_product_name(name):
    """ìƒí’ˆëª… ì •ì œ (ê°•í™”ëœ ë²„ì „)"""
    if not name:
        return name
    
    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    name = re.sub(r'(ë¦¬ë·°\s*\d+|ë³„ì |í• ì¸|ë°°ì†¡)', '', name)
    name = re.sub(r'(ì •ìƒê°€ê²©|íŒë§¤ê°€ê²©|ìµœê³ íŒë§¤ê°€)', '', name)
    name = re.sub(r'(ADADë€\?\s*íˆ´íŒ\s*ì—´ê¸°)', '', name)  # ê´‘ê³  ê´€ë ¨ í…ìŠ¤íŠ¸
    name = re.sub(r'(ê²€ìƒ‰\s*í•„í„°|ë¸Œëœë“œ\s*ì „ì²´ë³´ê¸°)', '', name)  # í•„í„° ê´€ë ¨ í…ìŠ¤íŠ¸
    name = re.sub(r'(\d+ë§Œì›\s*ì´í•˜|\d+ë§Œì›~\d+ë§Œì›)', '', name)  # ê°€ê²© ë²”ìœ„ í…ìŠ¤íŠ¸
    name = re.sub(r'(ì¸ê¸°|BEST|ì¶”ì²œ|ì„ ë¬¼)', '', name)  # ë§ˆì¼€íŒ… í…ìŠ¤íŠ¸
    name = re.sub(r'(ìƒˆë²½ë°°ì†¡|ë‹¹ì¼ë°°ì†¡|ë¬´ë£Œë°°ì†¡)', '', name)  # ë°°ì†¡ ê´€ë ¨
    
    # ì—°ì† ê³µë°± ì œê±°
    name = re.sub(r'\s+', ' ', name).strip()
    
    # ê¸¸ì´ ì œí•œ (ë” ì§§ê²Œ)
    if len(name) > 60:
        name = name[:60] + "..."
    
    return name

def search_ssg_products(keyword, page=1, limit=20):
    """ë©”ì¸ SSG ìƒí’ˆ ê²€ìƒ‰ í•¨ìˆ˜ (ë¹„ë™ê¸° ìš°ì„ , ë™ê¸° í´ë°±)"""
    try:
        if ASYNC_AVAILABLE:
            print("ğŸš€ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ì‚¬ìš©")
            return search_ssg_products_enhanced(keyword, page, limit)
        else:
            print("ğŸŒ ê¸°ì¡´ ë™ê¸° í¬ë¡¤ëŸ¬ ì‚¬ìš©")
            return search_ssg_products_legacy(keyword, page, limit)
    except Exception as e:
        print(f"âš ï¸ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ì˜¤ë¥˜, ë™ê¸° í¬ë¡¤ëŸ¬ë¡œ í´ë°±: {e}")
        return search_ssg_products_legacy(keyword, page, limit)

if __name__ == '__main__':
    print("=== SSG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    test_search()
    print("\n=== SSG ê°€ê²© ë¹„êµ í…ŒìŠ¤íŠ¸ ===")
    test_compare()
    print("\n=== ë‹¨ì¼ ìƒí’ˆ í…ŒìŠ¤íŠ¸ ===")
    test_single_product()