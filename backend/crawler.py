import requests
from bs4 import BeautifulSoup
import re
import time
import json
from urllib.parse import quote

# ìƒˆë¡œìš´ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ import
try:
    from async_crawler import search_ssg_products_enhanced
    ASYNC_AVAILABLE = True
    print("âœ… ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    ASYNC_AVAILABLE = False

def get_headers():
    """ê³µí†µ í—¤ë” ë°˜í™˜"""
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }

def search_ssg_products_legacy(keyword, page=1, limit=20):
    """SSGì—ì„œ ìƒí’ˆ ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""
    try:
        encoded_keyword = quote(keyword)
        search_url = f"https://www.ssg.com/search.ssg?target=all&query={encoded_keyword}&page={page}"
        
        headers = get_headers()
        response = requests.get(search_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        products = []
        
        print(f"ğŸ” SSG ê²€ìƒ‰ í˜ì´ì§€ ì ‘ê·¼ ì„±ê³µ: {search_url}")
        
        # ì‹¤ì œ SSG ìƒí’ˆ ì„ íƒìë“¤ (ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡° ê¸°ë°˜)
        product_selectors = [
            '.cunit_prod',  # SSG ë©”ì¸ ìƒí’ˆ ì»¨í…Œì´ë„ˆ
            '.cunit_item',  # ìƒí’ˆ ì•„ì´í…œ
            '.prod_item',   # ìƒí’ˆ ì•„ì´í…œ ëŒ€ì²´
            '.item_thmb',   # ì¸ë„¤ì¼ ì»¨í…Œì´ë„ˆ
            'div[class*="cunit"]',  # cunit ê´€ë ¨ í´ë˜ìŠ¤
            '[data-item-id]'  # ë°ì´í„° ì†ì„± ê¸°ë°˜
        ]
        
        product_elements = []
        for selector in product_selectors:
            elements = soup.select(selector)
            if elements:
                print(f"âœ… ì„ íƒì '{selector}'ë¡œ {len(elements)}ê°œ ìƒí’ˆ ë°œê²¬")
                product_elements = elements
                break
        
        if not product_elements:
            print("âš ï¸ ìƒí’ˆ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§í¬ ê¸°ë°˜ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
            # ë§í¬ ê¸°ë°˜ í´ë°±
            product_links = soup.select('a[href*="itemView.ssg"]')
            for link in product_links[:limit * 2]:
                href = link.get('href', '')
                if 'itemId=' in href and 'advertBidId' not in href:
                    product_elements.append(link.parent or link)
        
        print(f"ğŸ“¦ ì´ {len(product_elements)}ê°œ ìƒí’ˆ ìš”ì†Œ ë°œê²¬")
        
        # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (ì¤‘ë³µ ì œê±° ë¡œì§ ì¶”ê°€)
        seen_urls = set()
        seen_names = set()
        
        for element in product_elements[:limit * 2]:
            if len(products) >= limit:
                break
                
            try:
                product_info = extract_ssg_product_info(element, keyword)
                if product_info and product_info.get('name') and len(product_info['name']) > 5:
                    # ì¤‘ë³µ ì²´í¬
                    url = product_info.get('url', '')
                    name = product_info.get('name', '').strip()
                    
                    if (url not in seen_urls and 
                        name not in seen_names and 
                        len(name) > 5):
                        
                        products.append(product_info)
                        seen_urls.add(url)
                        seen_names.add(name)
                        print(f"âœ… ìƒí’ˆ ì¶”ì¶œ: {product_info['name'][:50]}...")
                    
            except Exception as e:
                print(f"âš ï¸ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"ğŸ¯ ìµœì¢… ì¶”ì¶œëœ ìƒí’ˆ: {len(products)}ê°œ")
        
        # ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ë”ë¯¸ ë°ì´í„°ë¡œ ë³´ì™„
        if len(products) < limit // 2:
            print("ğŸ“ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.")
            dummy_products = create_dummy_products(keyword, limit - len(products))
            products.extend(dummy_products)
        
        return products[:limit]
        
    except Exception as e:
        print(f"âŒ SSG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return create_dummy_products(keyword, limit)

def extract_ssg_product_info(element, keyword):
    """SSG ìƒí’ˆ ìš”ì†Œì—ì„œ ì •ë³´ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
    try:
        # 1. ìƒí’ˆ URL ì°¾ê¸°
        product_url = None
        link = element.find('a', href=re.compile(r'itemView\.ssg.*itemId='))
        if link:
            href = link.get('href', '')
            if href.startswith('/'):
                product_url = f"https://www.ssg.com{href}"
            else:
                product_url = href
        
        if not product_url:
            return None
        
        # 2. ìƒí’ˆëª… ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
        name = None
        
        # ë¨¼ì € ê°œë³„ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ì •í™•í•œ ìƒí’ˆëª… ê°€ì ¸ì˜¤ê¸°
        if product_url:
            try:
                page_response = requests.get(product_url, headers=get_headers(), timeout=5)
                if page_response.status_code == 200:
                    page_soup = BeautifulSoup(page_response.content, 'html.parser')
                    
                    # SSG ìƒí’ˆ í˜ì´ì§€ì˜ ì •í™•í•œ ìƒí’ˆëª… ì„ íƒì
                    page_name_selectors = [
                        'h2.cdtl_prd_nm',
                        'h1.cdtl_prd_nm',
                        '.prod_tit',
                        'title'
                    ]
                    
                    for selector in page_name_selectors:
                        name_elem = page_soup.select_one(selector)
                        if name_elem:
                            candidate_name = name_elem.get_text(strip=True)
                            if candidate_name and candidate_name != "SSG.COM" and len(candidate_name) > 10:
                                name = candidate_name
                                break
                    
                    if name:
                        print(f"âœ… ê°œë³„ í˜ì´ì§€ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ: {name[:50]}...")
            except:
                pass  # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # ê°œë³„ í˜ì´ì§€ì—ì„œ ì‹¤íŒ¨í•˜ë©´ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ì¶”ì¶œ
        if not name:
            name_selectors = [
                '.cunit_tit a',           # SSG ë©”ì¸ ìƒí’ˆëª…
                '.cunit_info .item_tit',  # ìƒí’ˆ ì •ë³´ ì œëª©
                '.prod_tit',              # ìƒí’ˆ ì œëª©
                '.item_tit',              # ì•„ì´í…œ ì œëª©
                '.cunit_prod .tit',       # ìœ ë‹› ì œëª©
                'a[href*="itemView"]'     # ë§í¬ í…ìŠ¤íŠ¸
            ]
            
            for selector in name_selectors:
                name_elem = element.select_one(selector)
                if name_elem:
                    candidate_name = name_elem.get_text(strip=True)
                    if candidate_name and len(candidate_name) > 5 and not is_generic_product_text(candidate_name):
                        name = candidate_name
                        break
            
            # ìƒí’ˆëª…ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
            if not name:
                all_text = element.get_text(strip=True)
                lines = [line.strip() for line in all_text.split('\n') if line.strip()]
                for line in lines:
                    if (len(line) > 10 and 
                        keyword.lower() in line.lower() and 
                        not is_generic_product_text(line)):
                        name = line
                        break
                
                if not name and lines:
                    # ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë¼ì¸ ì„ íƒ
                    for line in lines:
                        if len(line) > 10 and not is_generic_product_text(line):
                            name = line
                            break
                    
                    if not name:
                        name = f"{keyword} ìƒí’ˆ"
        
        # 3. ê°€ê²© ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
        price = 0
        
        # ë¨¼ì € ê°œë³„ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ì •í™•í•œ ê°€ê²© ê°€ì ¸ì˜¤ê¸°
        if product_url:
            try:
                page_response = requests.get(product_url, headers=get_headers(), timeout=5)
                if page_response.status_code == 200:
                    page_soup = BeautifulSoup(page_response.content, 'html.parser')
                    
                    # SSG ìƒí’ˆ í˜ì´ì§€ì˜ ì •í™•í•œ ê°€ê²© ì„ íƒì
                    page_price_selectors = [
                        '.cdtl_price .blind',      # ìƒì„¸ í˜ì´ì§€ ê°€ê²© (ìˆ¨ê¹€ í…ìŠ¤íŠ¸)
                        '.cdtl_old_price .blind',  # ì›ê°€
                        '.price_original',         # ì›ê°€
                        '.price_discount',         # í• ì¸ê°€
                        '.ssg_price'              # SSG ê°€ê²©
                    ]
                    
                    for selector in page_price_selectors:
                        price_elem = page_soup.select_one(selector)
                        if price_elem:
                            price_text = price_elem.get_text(strip=True)
                            price_matches = re.findall(r'(\d{1,3}(?:,\d{3})*)', price_text)
                            if price_matches:
                                try:
                                    candidate_price = int(price_matches[0].replace(',', ''))
                                    if 1000 <= candidate_price <= 50000000:
                                        price = candidate_price
                                        print(f"âœ… ê°œë³„ í˜ì´ì§€ì—ì„œ ê°€ê²© ì¶”ì¶œ: {price:,}ì›")
                                        break
                                except:
                                    continue
                    
                    if price > 0:
                        pass  # ê°€ê²©ì„ ì°¾ì•˜ìœ¼ë¯€ë¡œ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œëŠ” ì°¾ì§€ ì•ŠìŒ
            except:
                pass  # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # ê°œë³„ í˜ì´ì§€ì—ì„œ ì‹¤íŒ¨í•˜ë©´ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ì¶”ì¶œ
        if price == 0:
            price_selectors = [
                '.cunit_price .blind',     # SSG ê°€ê²© (ìˆ¨ê¹€ í…ìŠ¤íŠ¸)
                '.price_original',         # ì›ê°€
                '.price_discount',         # í• ì¸ê°€
                '.ssg_price',             # SSG ê°€ê²©
                '.price',                 # ì¼ë°˜ ê°€ê²©
                '[class*="price"]'        # ê°€ê²© ê´€ë ¨ í´ë˜ìŠ¤
            ]
            
            for selector in price_selectors:
                price_elem = element.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    price_matches = re.findall(r'(\d{1,3}(?:,\d{3})*)', price_text)
                    if price_matches:
                        try:
                            candidate_price = int(price_matches[0].replace(',', ''))
                            if 1000 <= candidate_price <= 50000000:
                                price = candidate_price
                                break
                        except:
                            continue
            
            # ê°€ê²©ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì°¾ê¸°
            if price == 0:
                all_text = element.get_text()
                price_matches = re.findall(r'(\d{1,3}(?:,\d{3})*)\s*ì›', all_text)
                if price_matches:
                    for match in price_matches:
                        try:
                            candidate_price = int(match.replace(',', ''))
                            if 1000 <= candidate_price <= 50000000:
                                price = candidate_price
                                break
                        except:
                            continue
        
        # 4. ì´ë¯¸ì§€ URL ì¶”ì¶œ
        image_url = None
        img_selectors = [
            '.cunit_img img',         # SSG ìƒí’ˆ ì´ë¯¸ì§€
            '.prod_img img',          # ìƒí’ˆ ì´ë¯¸ì§€
            '.item_img img',          # ì•„ì´í…œ ì´ë¯¸ì§€
            'img'                     # ëª¨ë“  ì´ë¯¸ì§€
        ]
        
        for selector in img_selectors:
            img_elem = element.select_one(selector)
            if img_elem:
                image_url = img_elem.get('src') or img_elem.get('data-src') or img_elem.get('data-original')
                if image_url:
                    if image_url.startswith('//'):
                        image_url = f"https:{image_url}"
                    elif image_url.startswith('/'):
                        image_url = f"https://www.ssg.com{image_url}"
                    
                    # ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸
                    if any(ext in image_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                        break
                    else:
                        image_url = None
        
        # 5. ë¸Œëœë“œ ì¶”ì¶œ
        brand = extract_brand_from_element(element, name or "")
        
        # 6. ìƒí’ˆëª… ì •ì œ
        if name:
            name = clean_product_name(name)
        else:
            name = f"{keyword} ê´€ë ¨ ìƒí’ˆ"
        
        return {
            'name': name,
            'price': price,
            'url': product_url,
            'image_url': image_url,
            'brand': brand,
            'source': 'SSG'
        }
        
    except Exception as e:
        print(f"âš ï¸ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def extract_brand_from_element(element, product_name):
    """ìš”ì†Œì—ì„œ ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # 1. ë¸Œëœë“œ ê´€ë ¨ í´ë˜ìŠ¤ì—ì„œ ì°¾ê¸°
        brand_selectors = [
            '.cunit_brand',           # SSG ë¸Œëœë“œ
            '.brand_name',            # ë¸Œëœë“œëª…
            '.brand',                 # ë¸Œëœë“œ
            '.maker',                 # ì œì¡°ì‚¬
            '.vendor'                 # íŒë§¤ì
        ]
        
        for selector in brand_selectors:
            brand_elem = element.select_one(selector)
            if brand_elem:
                brand_text = brand_elem.get_text(strip=True)
                if brand_text and len(brand_text) < 50:
                    return brand_text
        
        # 2. ìƒí’ˆëª…ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
        if product_name:
            known_brands = [
                'APPLE', 'ì‚¼ì„±', 'SAMSUNG', 'LG', 'ë‚˜ì´í‚¤', 'NIKE', 
                'ì•„ë””ë‹¤ìŠ¤', 'ADIDAS', 'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘'
            ]
            
            product_upper = product_name.upper()
            for brand in known_brands:
                if brand.upper() in product_upper:
                    return brand
            
            # ì²« ë‹¨ì–´ê°€ ë¸Œëœë“œì¼ ê°€ëŠ¥ì„±
            first_word = product_name.split()[0] if product_name.split() else ''
            if first_word and 2 < len(first_word) < 20:
                return first_word
        
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'
        
    except Exception:
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'

def is_generic_product_text(text):
    """ì¼ë°˜ì ì¸/ì˜ë¯¸ì—†ëŠ” ìƒí’ˆ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
    if not text:
        return True
    
    text_lower = text.lower()
    
    # ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ íŒ¨í„´ë“¤
    generic_patterns = [
        'í•¨ê»˜ ë³´ë©´ ì¢‹ì€',
        'ê´€ë ¨ ìƒí’ˆ',
        'ì¶”ì²œ ìƒí’ˆ',
        'ì¸ê¸° ìƒí’ˆ',
        'ë² ìŠ¤íŠ¸',
        'í• ì¸',
        'ë¬´ë£Œë°°ì†¡',
        'ë‹¹ì¼ë°°ì†¡',
        'ë¦¬ë·°',
        'ë³„ì ',
        'í‰ì ',
        'ë”ë³´ê¸°',
        'ìì„¸íˆ',
        'ìƒí’ˆì •ë³´',
        'ìƒí’ˆìƒì„¸',
        'ë¸Œëœë“œ ì „ì²´ë³´ê¸°',
        'ê²€ìƒ‰ í•„í„°',
        'ì •ë ¬',
        'ê°€ê²©ëŒ€',
        'ë°°ì†¡ë¹„',
        'ì ë¦½ê¸ˆ'
    ]
    
    for pattern in generic_patterns:
        if pattern in text_lower:
            return True
    
    # ë„ˆë¬´ ì§§ê±°ë‚˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
    if len(text) < 5 or text.isdigit():
        return True
    
    # íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš°
    if re.match(r'^[^\wê°€-í£]+$', text):
        return True
    
    return False

def create_dummy_products(keyword, limit=5):
    """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ìƒí’ˆ ë°ì´í„° ìƒì„±"""
    import random
    
    dummy_products = []
    base_prices = [29900, 49900, 79900, 99900, 149900, 199900, 299900]
    
    for i in range(min(limit, 5)):
        price = random.choice(base_prices) + random.randint(-10000, 10000)
        dummy_products.append({
            'name': f"{keyword} ê´€ë ¨ ìƒí’ˆ {i+1} - í…ŒìŠ¤íŠ¸ ë°ì´í„°",
            'price': max(price, 10000),
            'url': f"https://www.ssg.com/item/itemView.ssg?itemId=test{i+1}",
            'image_url': f"https://via.placeholder.com/200x200?text={keyword}+{i+1}",
            'brand': f"í…ŒìŠ¤íŠ¸ ë¸Œëœë“œ {i+1}",
            'source': 'SSG'
        })
    
    return dummy_products

def crawl_ssg_product(url):
    """SSG ìƒí’ˆ ì •ë³´ í¬ë¡¤ë§ (ê°œì„ ëœ ë²„ì „)"""
    try:
        headers = get_headers()
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ìƒí’ˆëª… ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        name_selectors = [
            'h2.cdtl_prd_nm',
            'h1.cdtl_prd_nm',
            '.prod_tit',
            '.item_tit',
            'title'
        ]
        
        name = None
        for selector in name_selectors:
            name_element = soup.select_one(selector)
            if name_element:
                name = name_element.get_text(strip=True)
                if name and name != "SSG.COM":
                    break
        
        if not name:
            name = "ìƒí’ˆëª… ì—†ìŒ"
        
        # ê°€ê²© ì¶”ì¶œ (ëŒ€í­ ê°œì„ ëœ íŒ¨í„´)
        price = 0
        
        # 1. ë©”ì¸ ê°€ê²© ì„ íƒìë“¤ (ì‹¤ì œ SSG êµ¬ì¡° ê¸°ë°˜)
        main_price_selectors = [
            '.cdtl_price .blind',      # ë©”ì¸ ê°€ê²© (ìˆ¨ê¹€ í…ìŠ¤íŠ¸)
            '.cdtl_old_price .blind',  # ì›ê°€ (ìˆ¨ê¹€ í…ìŠ¤íŠ¸)
            '.price_original',         # ì›ê°€
            '.price_discount',         # í• ì¸ê°€
            '.ssg_price',             # SSG ê°€ê²©
            '.price'                  # ì¼ë°˜ ê°€ê²©
        ]
        
        for selector in main_price_selectors:
            price_element = soup.select_one(selector)
            if price_element:
                price_text = price_element.get_text(strip=True)
                # ì—¬ëŸ¬ ê°€ê²© íŒ¨í„´ ì‹œë„
                price_patterns = [
                    r'íŒë§¤ê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
                    r'ì •ìƒê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
                    r'í• ì¸ê°€\s*(\d{1,3}(?:,\d{3})*)',
                    r'(\d{1,3}(?:,\d{3})*)\s*ì›',
                    r'(\d{1,3}(?:,\d{3})*)'
                ]
                
                for pattern in price_patterns:
                    price_matches = re.findall(pattern, price_text)
                    if price_matches:
                        try:
                            candidate_price = int(price_matches[0].replace(',', ''))
                            if 1000 <= candidate_price <= 50000000:  # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„
                                price = candidate_price
                                print(f"âœ… ê°€ê²© ì¶”ì¶œ ì„±ê³µ: {price:,}ì› (ì„ íƒì: {selector})")
                                break
                        except:
                            continue
                
                if price > 0:
                    break
        
        # 2. ê°€ê²©ì„ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ì „ì²´ í˜ì´ì§€ì—ì„œ ê²€ìƒ‰
        if price == 0:
            print("âš ï¸ ë©”ì¸ ì„ íƒìì—ì„œ ê°€ê²©ì„ ì°¾ì§€ ëª»í•¨. ì „ì²´ í˜ì´ì§€ ê²€ìƒ‰ ì¤‘...")
            page_text = soup.get_text()
            
            # ë” ê´‘ë²”ìœ„í•œ ê°€ê²© íŒ¨í„´
            comprehensive_patterns = [
                r'íŒë§¤ê°€ê²©[:\s]*(\d{1,3}(?:,\d{3})*)',
                r'ì •ìƒê°€ê²©[:\s]*(\d{1,3}(?:,\d{3})*)',
                r'í• ì¸ê°€[:\s]*(\d{1,3}(?:,\d{3})*)',
                r'ê°€ê²©[:\s]*(\d{1,3}(?:,\d{3})*)',
                r'(\d{1,3}(?:,\d{3})*)\s*ì›',
                r'â‚©\s*(\d{1,3}(?:,\d{3})*)',
                r'KRW\s*(\d{1,3}(?:,\d{3})*)'
            ]
            
            all_prices = []
            for pattern in comprehensive_patterns:
                matches = re.findall(pattern, page_text)
                for match in matches:
                    try:
                        candidate_price = int(match.replace(',', ''))
                        if 10000 <= candidate_price <= 10000000:  # ë” ë„“ì€ ë²”ìœ„
                            all_prices.append(candidate_price)
                    except:
                        continue
            
            if all_prices:
                # ê°€ê²©ë“¤ì„ ì •ë ¬í•˜ê³  ì¤‘ê°„ê°’ ì„ íƒ (ì´ìƒì¹˜ ì œê±°)
                all_prices.sort()
                if len(all_prices) == 1:
                    price = all_prices[0]
                else:
                    # ì¤‘ê°„ê°’ë“¤ ì¤‘ì—ì„œ ì„ íƒ
                    mid_start = len(all_prices) // 3
                    mid_end = len(all_prices) * 2 // 3
                    mid_prices = all_prices[mid_start:mid_end] if mid_end > mid_start else all_prices
                    price = mid_prices[0] if mid_prices else all_prices[0]
                
                print(f"âœ… ì „ì²´ í˜ì´ì§€ì—ì„œ ê°€ê²© ì¶”ì¶œ: {price:,}ì›")
        
        # 3. ì—¬ì „íˆ ê°€ê²©ì´ ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ì—ì„œ ì°¾ê¸°
        if price == 0:
            print("âš ï¸ ìŠ¤í¬ë¦½íŠ¸ íƒœê·¸ì—ì„œ ê°€ê²© ê²€ìƒ‰ ì¤‘...")
            script_tags = soup.find_all('script')
            for script in script_tags:
                if script.string:
                    script_text = script.string
                    # JSON ë°ì´í„°ì—ì„œ ê°€ê²© ì°¾ê¸°
                    price_patterns = [
                        r'"price"[:\s]*(\d+)',
                        r'"salePrice"[:\s]*(\d+)',
                        r'"originalPrice"[:\s]*(\d+)',
                        r'"sellPrice"[:\s]*(\d+)'
                    ]
                    
                    for pattern in price_patterns:
                        matches = re.findall(pattern, script_text)
                        if matches:
                            try:
                                candidate_price = int(matches[0])
                                if 1000 <= candidate_price <= 50000000:
                                    price = candidate_price
                                    print(f"âœ… ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê°€ê²© ì¶”ì¶œ: {price:,}ì›")
                                    break
                            except:
                                continue
                    
                    if price > 0:
                        break
        
        # ì´ë¯¸ì§€ URL ì¶”ì¶œ (ê°œì„ ëœ íŒ¨í„´)
        image_url = None
        img_selectors = [
            '.cdtl_img_wrap img',
            '.prod_img img',
            '.item_img img',
            '.product_img img',
            'img[src*="item"]',
            'img[data-src*="item"]'
        ]
        
        for selector in img_selectors:
            img_element = soup.select_one(selector)
            if img_element:
                image_url = img_element.get('src') or img_element.get('data-src') or img_element.get('data-original')
                if image_url:
                    if image_url.startswith('//'):
                        image_url = f"https:{image_url}"
                    elif image_url.startswith('/'):
                        image_url = f"https://www.ssg.com{image_url}"
                    
                    # ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸
                    if any(ext in image_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                        break
                    else:
                        image_url = None
        
        return {
            'name': name,
            'price': price,
            'url': url,
            'image_url': image_url
        }
        
    except Exception as e:
        print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None

def compare_products(keyword, limit=10):
    """ìƒí’ˆ ê²€ìƒ‰ ë° ê°€ê²© ë¹„êµ"""
    try:
        products = search_ssg_products(keyword, limit=limit)
        
        if not products:
            return []
        
        # ê°€ê²©ìˆœ ì •ë ¬
        products_sorted = sorted(products, key=lambda x: x['price'] if x['price'] > 0 else float('inf'))
        
        # ê°€ê²© ë¹„êµ ì •ë³´ ì¶”ê°€
        for i, product in enumerate(products_sorted):
            if i == 0 and product['price'] > 0:
                product['price_rank'] = 'ìµœì €ê°€'
                product['price_diff'] = 0
            elif product['price'] > 0:
                lowest_price = products_sorted[0]['price']
                product['price_diff'] = product['price'] - lowest_price
                product['price_rank'] = f"{i+1}ìœ„"
            else:
                product['price_rank'] = 'ê°€ê²© ì •ë³´ ì—†ìŒ'
                product['price_diff'] = 0
        
        return products_sorted
        
    except Exception as e:
        print(f"ìƒí’ˆ ë¹„êµ ì˜¤ë¥˜: {e}")
        return []

def extract_product_name_from_ssg(link, product_url, keyword):
    """SSGì—ì„œ ì •í™•í•œ ìƒí’ˆëª… ì¶”ì¶œ"""
    try:
        # 1. ë§í¬ í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ
        name = link.get_text(strip=True)
        
        # 2. ë§í¬ í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ë©´ ì£¼ë³€ ìš”ì†Œì—ì„œ ì°¾ê¸°
        if not name or len(name) < 10:
            current = link.parent
            for level in range(7):  # ë” ë§ì€ ë ˆë²¨ í™•ì¸
                if current:
                    # ìƒí’ˆëª… ê´€ë ¨ í´ë˜ìŠ¤ ì°¾ê¸°
                    name_selectors = [
                        '.item_tit', '.prod_tit', '.product_title', '.title',
                        '.item_name', '.prod_name', '.product_name', '.name',
                        '.goods_name', '.goods_title', '.item_info_tit'
                    ]
                    
                    for selector in name_selectors:
                        name_elem = current.select_one(selector)
                        if name_elem:
                            candidate_name = name_elem.get_text(strip=True)
                            if candidate_name and len(candidate_name) > 10:
                                name = candidate_name
                                break
                    
                    if name and len(name) > 10:
                        break
                    
                    # í´ë˜ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ í…ìŠ¤íŠ¸ íŒ¨í„´ìœ¼ë¡œ ì°¾ê¸°
                    current_text = current.get_text(strip=True)
                    if current_text and 15 < len(current_text) < 300:
                        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                        clean_text = re.sub(r'(ë¦¬ë·°|ë³„ì |ê°¯ìˆ˜|í• ì¸ìœ¨|ì •ìƒê°€ê²©|íŒë§¤ê°€ê²©|ë°°ì†¡|ë¬´ë£Œë°°ì†¡|ë‹¹ì¼ë°°ì†¡).*', '', current_text)
                        clean_text = re.sub(r'(\d{1,3}(?:,\d{3})*ì›).*', '', clean_text)  # ê°€ê²© ì´í›„ í…ìŠ¤íŠ¸ ì œê±°
                        
                        if len(clean_text) > 15:
                            name = clean_text[:150]
                            break
                    
                    current = current.parent
                else:
                    break
        
        # 3. ê°œë³„ í˜ì´ì§€ ì ‘ê·¼ì€ ì œê±° (ì†ë„ ê°œì„ ì„ ìœ„í•´)
        
        # 4. ìƒí’ˆëª… ì •ì œ
        if name:
            # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            name = re.sub(r'(ë¦¬ë·°\s*\d+|ë³„ì \s*[\d.]+|ê°¯ìˆ˜\s*\d+)', '', name)
            name = re.sub(r'(í• ì¸ìœ¨\s*\d+%|ì •ìƒê°€ê²©|íŒë§¤ê°€ê²©)', '', name)
            name = re.sub(r'(ë°°ì†¡|ë¬´ë£Œë°°ì†¡|ë‹¹ì¼ë°°ì†¡|íƒë°°)', '', name)
            name = re.sub(r'(ì¹´ë“œí• ì¸|ì¦‰ì‹œí• ì¸|ì¶”ê°€í• ì¸)', '', name)
            name = re.sub(r'(ì‚¬ì€í’ˆ|ì¦ì •|ì´ë²¤íŠ¸)', '', name)
            name = re.sub(r'\s+', ' ', name).strip()  # ì—°ì† ê³µë°± ì œê±°
            
            # ìƒí’ˆëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(name) > 100:
                name = name[:100] + "..."
            
            return name
        
        # 5. ìµœí›„ ìˆ˜ë‹¨: ê¸°ë³¸ê°’ ë°˜í™˜
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"
        
    except Exception as e:
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"

def get_product_name_from_ssg_page(product_url):
    """SSG ê°œë³„ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ"""
    try:
        headers = get_headers()
        response = requests.get(product_url, headers=headers, timeout=8)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # SSG ìƒí’ˆ í˜ì´ì§€ì˜ ìƒí’ˆëª… ì„ íƒìë“¤
        name_selectors = [
            'h2.cdtl_prd_nm',
            'h1.cdtl_prd_nm', 
            '.prod_tit',
            '.item_tit',
            '.product_title',
            '.goods_name',
            'title'
        ]
        
        for selector in name_selectors:
            name_elem = soup.select_one(selector)
            if name_elem:
                name = name_elem.get_text(strip=True)
                if name and name != "SSG.COM" and len(name) > 10:
                    return name
        
        return None
        
    except Exception as e:
        return None

def extract_brand_from_ssg(link, product_name):
    """SSGì—ì„œ ë¸Œëœë“œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # 1. ë§í¬ ì£¼ë³€ ìš”ì†Œì—ì„œ ë¸Œëœë“œ ì •ë³´ ì°¾ê¸°
        current = link.parent
        for _ in range(5):  # ìµœëŒ€ 5ë‹¨ê³„ ë¶€ëª¨ê¹Œì§€ í™•ì¸
            if current:
                # ë¸Œëœë“œ ê´€ë ¨ í´ë˜ìŠ¤ë‚˜ ì†ì„± ì°¾ê¸°
                brand_selectors = [
                    '.brand', '.brand_name', '.brand_info', '.brand_txt',
                    '.maker', '.maker_name', '.company', '.company_name',
                    '.vendor', '.vendor_name', '.seller', '.seller_name'
                ]
                
                for selector in brand_selectors:
                    brand_elem = current.select_one(selector)
                    if brand_elem:
                        brand_text = brand_elem.get_text(strip=True)
                        if brand_text and len(brand_text) < 50:  # ë¸Œëœë“œëª…ì€ ë³´í†µ ì§§ìŒ
                            return brand_text
                
                # í…ìŠ¤íŠ¸ì—ì„œ ë¸Œëœë“œ íŒ¨í„´ ì°¾ê¸°
                current_text = current.get_text()
                brand_match = re.search(r'ë¸Œëœë“œ[:\s]*([ê°€-í£A-Za-z0-9\s&]+)', current_text)
                if brand_match:
                    brand = brand_match.group(1).strip()
                    if len(brand) < 30:
                        return brand
                
                current = current.parent
            else:
                break
        
        # 2. ìƒí’ˆëª…ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
        if product_name:
            # ì˜ ì•Œë ¤ì§„ ë¸Œëœë“œ íŒ¨í„´
            known_brands = [
                # ì „ìì œí’ˆ
                'APPLE', 'ì‚¼ì„±', 'SAMSUNG', 'LG', 'ì†Œë‹ˆ', 'SONY', 'í™”ì›¨ì´', 'HUAWEI',
                'ìƒ¤ì˜¤ë¯¸', 'XIAOMI', 'êµ¬ê¸€', 'GOOGLE', 'ë§ˆì´í¬ë¡œì†Œí”„íŠ¸', 'MICROSOFT',
                # íŒ¨ì…˜
                'ë‚˜ì´í‚¤', 'NIKE', 'ì•„ë””ë‹¤ìŠ¤', 'ADIDAS', 'í‘¸ë§ˆ', 'PUMA', 'ì–¸ë”ì•„ë¨¸', 'UNDER ARMOUR',
                'ìœ ë‹ˆí´ë¡œ', 'UNIQLO', 'ìë¼', 'ZARA', 'H&M',
                # ì‹í’ˆ
                'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'íŒ”ë„', 'ë¡¯ë°', 'LOTTE', 'CJ', 'ë™ì›',
                # í™”ì¥í’ˆ
                'ì•„ëª¨ë ˆí¼ì‹œí”½', 'ë”í˜ì´ìŠ¤ìƒµ', 'ì´ë‹ˆìŠ¤í”„ë¦¬', 'ì—ë›°ë“œ', 'ë¯¸ìƒ¤', 'MISSHA',
                # ìƒí™œìš©í’ˆ
                'P&G', 'ìœ í•œí‚´ë²Œë¦¬', 'ì• ê²½', 'ë¼ì´ì˜¨', 'LION'
            ]
            
            product_upper = product_name.upper()
            for brand in known_brands:
                if brand.upper() in product_upper:
                    return brand
            
            # ìƒí’ˆëª… ì²« ë‹¨ì–´ê°€ ë¸Œëœë“œì¼ ê°€ëŠ¥ì„±
            first_word = product_name.split()[0] if product_name.split() else ''
            if first_word and len(first_word) > 1 and len(first_word) < 20:
                # ì˜ë¬¸ì´ë‚˜ í•œê¸€ë¡œë§Œ êµ¬ì„±ëœ ê²½ìš°
                if re.match(r'^[A-Za-zê°€-í£]+$', first_word):
                    return first_word
        
        # 3. ê¸°ë³¸ê°’ ë°˜í™˜
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'
        
    except Exception as e:
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'

def extract_price_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ê°€ê²© ì¶”ì¶œ"""
    if not text:
        return 0
    
    # ì—¬ëŸ¬ ê°€ê²© íŒ¨í„´ ì‹œë„
    patterns = [
        r'íŒë§¤ê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
        r'ì •ìƒê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
        r'(\d{1,3}(?:,\d{3})*)\s*ì›',
        r'ê°€ê²©\s*(\d{1,3}(?:,\d{3})*)',
        r'(\d{1,3}(?:,\d{3})*)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        if matches:
            # ê°€ì¥ í° ìˆ«ìë¥¼ ê°€ê²©ìœ¼ë¡œ ê°„ì£¼ (í• ì¸ê°€ë³´ë‹¤ ì •ê°€ê°€ í´ ìˆ˜ ìˆìŒ)
            prices = [int(match.replace(',', '')) for match in matches]
            valid_prices = [p for p in prices if 1000 <= p <= 10000000]  # í•©ë¦¬ì ì¸ ê°€ê²© ë²”ìœ„
            if valid_prices:
                return min(valid_prices)  # ìµœì €ê°€ ë°˜í™˜
    
    return 0

def get_product_price_from_page(url):
    """ê°œë³„ ìƒí’ˆ í˜ì´ì§€ì—ì„œ ê°€ê²© ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        headers = get_headers()
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê°€ê²© ì„ íƒìë“¤
        price_selectors = [
            '.cdtl_old_price .blind',
            '.cdtl_price .blind', 
            '.price_original',
            '.price_discount',
            '.ssg_price',
            '.price'
        ]
        
        for selector in price_selectors:
            price_elem = soup.select_one(selector)
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                price = extract_price_from_text(price_text)
                if price > 0:
                    return price
        
        # ì „ì²´ í˜ì´ì§€ì—ì„œ ê°€ê²© íŒ¨í„´ ì°¾ê¸°
        page_text = soup.get_text()
        price = extract_price_from_text(page_text)
        return price
        
    except Exception as e:
        print(f"ê°œë³„ í˜ì´ì§€ ê°€ê²© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return 0

def test_search():
    """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    keyword = "ì•„ì´í°"
    print(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼:")
    products = search_ssg_products(keyword, limit=3)
    
    for i, product in enumerate(products, 1):
        print(f"{i}. {product['name'][:50]}...")
        
        # ê°€ê²©ì´ 0ì´ë©´ ê°œë³„ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        if product['price'] == 0 and product['url'] and 'itemView.ssg' in product['url']:
            print(f"   ê°œë³„ í˜ì´ì§€ì—ì„œ ê°€ê²© í™•ì¸ ì¤‘...")
            product['price'] = get_product_price_from_page(product['url'])
        
        print(f"   ê°€ê²©: {product['price']:,}ì›")
        print(f"   ë¸Œëœë“œ: {product['brand']}")
        print(f"   URL: {product['url']}")
        print()

def test_compare():
    """ê°€ê²© ë¹„êµ í…ŒìŠ¤íŠ¸"""
    keyword = "ë¬´ì„ ì´ì–´í°"
    print(f"'{keyword}' ê°€ê²© ë¹„êµ:")
    products = compare_products(keyword, limit=3)
    
    for product in products:
        print(f"[{product['price_rank']}] {product['name'][:50]}...")
        print(f"ê°€ê²©: {product['price']:,}ì› (+{product['price_diff']:,}ì›)")
        print(f"ë¸Œëœë“œ: {product['brand']}")
        print()

def test_single_product():
    """ë‹¨ì¼ ìƒí’ˆ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
    test_url = "https://www.ssg.com/item/itemView.ssg?itemId=1000618003010"
    print(f"ë‹¨ì¼ ìƒí’ˆ í…ŒìŠ¤íŠ¸: {test_url}")
    result = crawl_ssg_product(test_url)
    if result:
        print(f"ìƒí’ˆëª…: {result['name']}")
        print(f"ê°€ê²©: {result['price']:,}ì›")
        print(f"ì´ë¯¸ì§€: {result['image_url']}")
    else:
        print("í¬ë¡¤ë§ ì‹¤íŒ¨")

def extract_product_name_fast(link, keyword):
    """ë¹ ë¥¸ ìƒí’ˆëª… ì¶”ì¶œ (ì™„ì „íˆ ìƒˆë¡œìš´ ì ‘ê·¼ë²•)"""
    try:
        # 1. ë§í¬ì™€ ì£¼ë³€ ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        all_texts = []
        
        # ë§í¬ ìì²´ í…ìŠ¤íŠ¸
        link_text = link.get_text(strip=True)
        if link_text:
            all_texts.append(link_text)
        
        # ë¶€ëª¨ ìš”ì†Œë“¤ì˜ í…ìŠ¤íŠ¸ (ë” ê´‘ë²”ìœ„í•˜ê²Œ)
        current = link.parent
        for level in range(8):  # ë” ë§ì€ ë ˆë²¨ í™•ì¸
            if current:
                # ëª¨ë“  ìì‹ í…ìŠ¤íŠ¸ ë…¸ë“œ ìˆ˜ì§‘
                text_nodes = current.find_all(text=True)
                for text_node in text_nodes:
                    text = text_node.strip()
                    if text and len(text) > 5:
                        all_texts.append(text)
                
                # íŠ¹ì • íƒœê·¸ë“¤ì˜ í…ìŠ¤íŠ¸ë„ ìˆ˜ì§‘
                for tag in ['span', 'div', 'p', 'h1', 'h2', 'h3', 'strong', 'em']:
                    elements = current.find_all(tag)
                    for elem in elements[:10]:  # ê° íƒœê·¸ë‹¹ ìµœëŒ€ 10ê°œ
                        elem_text = elem.get_text(strip=True)
                        if elem_text and len(elem_text) > 5:
                            all_texts.append(elem_text)
                
                current = current.parent
            else:
                break
        
        # 2. ìˆ˜ì§‘ëœ í…ìŠ¤íŠ¸ë“¤ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ìƒí’ˆëª… ì°¾ê¸°
        best_candidates = []
        
        for text in all_texts:
            if not text or len(text) < 10:
                continue
            
            # í…ìŠ¤íŠ¸ ì •ì œ
            cleaned_text = clean_text_line(text)
            if not cleaned_text or len(cleaned_text) < 10:
                continue
            
            # ìƒí’ˆëª… ì ìˆ˜ ê³„ì‚°
            score = calculate_product_name_score(cleaned_text, keyword)
            if score > 0:
                best_candidates.append((cleaned_text, score))
        
        # 3. ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìƒí’ˆëª… ì„ íƒ
        if best_candidates:
            best_candidates.sort(key=lambda x: x[1], reverse=True)
            best_name = best_candidates[0][0]
            return clean_product_name(best_name[:120])
        
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"
        
    except Exception:
        return f"{keyword} ê´€ë ¨ ìƒí’ˆ"

def calculate_product_name_score(text, keyword):
    """ìƒí’ˆëª… ì í•©ì„± ì ìˆ˜ ê³„ì‚°"""
    if not text or is_generic_text(text):
        return 0
    
    score = 0
    text_lower = text.lower()
    keyword_lower = keyword.lower()
    
    # ê¸°ë³¸ ì ìˆ˜
    score += 10
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ë†’ì€ ì ìˆ˜
    if keyword_lower in text_lower:
        score += 50
    
    # ë¸Œëœë“œëª… í¬í•¨ ì‹œ ì ìˆ˜ ì¶”ê°€
    brands = [
        'apple', 'ì‚¼ì„±', 'samsung', 'lg', 'ë‚˜ì´í‚¤', 'nike', 'adidas', 
        'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'íŒ”ë„', 'ë¡¯ë°', 'lotte', 'cj',
        'ì•„ëª¨ë ˆ', 'ì´ë‹ˆìŠ¤í”„ë¦¬', 'ì—ë›°ë“œ', 'ë¯¸ìƒ¤', 'ë”í˜ì´ìŠ¤ìƒµ',
        'ì§€ì˜¤ë‹¤ë…¸', 'ìœ ë‹ˆí´ë¡œ', 'uniqlo', 'ìë¼', 'zara'
    ]
    
    for brand in brands:
        if brand in text_lower:
            score += 30
            break
    
    # ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì ìˆ˜ ì¶”ê°€
    product_keywords = [
        'gb', 'í”„ë¡œ', 'ë§¥ìŠ¤', 'ë¯¸ë‹ˆ', 'í”ŒëŸ¬ìŠ¤', 'ìš¸íŠ¸ë¼', 'ì—ì–´',
        'í‹°ì…”ì¸ ', 'í›„ë“œ', 'ë°”ì§€', 'ì›í”¼ìŠ¤', 'ìŠ¤ì»¤íŠ¸', 'ìì¼“',
        'ìŠ¤ë‹ˆì»¤ì¦ˆ', 'ë¶€ì¸ ', 'ìƒŒë“¤', 'ìŠ¬ë¦¬í¼',
        'í¬ë¦¼', 'ë¡œì…˜', 'ì„¸ëŸ¼', 'ë§ˆìŠ¤í¬', 'í´ë Œì €',
        'ë…¸íŠ¸ë¶', 'íƒœë¸”ë¦¿', 'ìŠ¤ë§ˆíŠ¸í°', 'ì´ì–´í°', 'ì¼€ì´ìŠ¤'
    ]
    
    for keyword in product_keywords:
        if keyword in text_lower:
            score += 20
            break
    
    # ëª¨ë¸ëª…ì´ë‚˜ ì œí’ˆ ì½”ë“œ í¬í•¨ ì‹œ ì ìˆ˜ ì¶”ê°€
    if re.search(r'[A-Z0-9]{3,}', text):
        score += 15
    
    # ê°€ê²©ì´ë‚˜ ë¦¬ë·° ì •ë³´ê°€ í¬í•¨ëœ ê²½ìš° ì ìˆ˜ ê°ì†Œ
    if any(word in text_lower for word in ['ì›', 'ë¦¬ë·°', 'ë³„ì ', 'í• ì¸', 'ë°°ì†¡']):
        score -= 20
    
    # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ í…ìŠ¤íŠ¸ ì ìˆ˜ ê°ì†Œ
    if len(text) < 15 or len(text) > 150:
        score -= 10
    
    return max(0, score)

def clean_text_line(text):
    """í…ìŠ¤íŠ¸ ë¼ì¸ ì •ì œ (ê°œì„ ëœ ë²„ì „)"""
    if not text:
        return ""
    
    # íŒë§¤ê°€ê²© ì´ì „ê¹Œì§€ë§Œ ì¶”ì¶œ (ìƒí’ˆëª… ë¶€ë¶„)
    text = re.sub(r'íŒë§¤ê°€ê²©.*', '', text)
    # ê°€ê²© ì´í›„ í…ìŠ¤íŠ¸ ì œê±°
    text = re.sub(r'(\d{1,3}(?:,\d{3})*ì›).*', '', text)
    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    text = re.sub(r'(ë¦¬ë·°|ë³„ì |í• ì¸|ë°°ì†¡|ë¬´ë£Œë°°ì†¡|ë‹¹ì¼ë°°ì†¡|íƒë°°).*', '', text)
    text = re.sub(r'(ì¹´ë“œí• ì¸|ì¦‰ì‹œí• ì¸|ì¶”ê°€í• ì¸|ì‚¬ì€í’ˆ|ì¦ì •).*', '', text)
    text = re.sub(r'(100gë‹¹|ê°œë‹¹|mlë‹¹).*', '', text)  # ë‹¨ìœ„ë‹¹ ê°€ê²© ì œê±°
    # ì—°ì† ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def is_generic_text(text):
    """ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
    if not text:
        return True
    
    generic_patterns = [
        r'^(ìƒí’ˆ|ì œí’ˆ|ì•„ì´í…œ)$',
        r'^(ì´ë¯¸ì§€|ì‚¬ì§„|ê·¸ë¦¼)$',
        r'^(ë§í¬|ë°”ë¡œê°€ê¸°)$',
        r'^(ë”ë³´ê¸°|ìì„¸íˆ)$',
        r'^\d+$',  # ìˆ«ìë§Œ
        r'^[ê°€-í£]{1,2}$',  # í•œê¸€ 1-2ì
    ]
    
    for pattern in generic_patterns:
        if re.match(pattern, text.strip()):
            return True
    
    return False

def has_product_keywords(text, keyword):
    """ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    if not text:
        return False
    
    text_lower = text.lower()
    keyword_lower = keyword.lower()
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    if keyword_lower in text_lower:
        return True
    
    # ë¸Œëœë“œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    brand_keywords = [
        'apple', 'ì‚¼ì„±', 'samsung', 'lg', 'ë‚˜ì´í‚¤', 'nike', 'adidas',
        'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'íŒ”ë„', 'ë¡¯ë°', 'lotte'
    ]
    
    for brand in brand_keywords:
        if brand in text_lower:
            return True
    
    # ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    product_keywords = ['gb', 'í”„ë¡œ', 'ë§¥ìŠ¤', 'ë¯¸ë‹ˆ', 'í”ŒëŸ¬ìŠ¤', 'ìš¸íŠ¸ë¼']
    for prod_keyword in product_keywords:
        if prod_keyword in text_lower:
            return True
    
    return False

def extract_price_fast(text):
    """ë¹ ë¥¸ ê°€ê²© ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    if not text:
        return 0
    
    # ê°€ì¥ ê°„ë‹¨í•œ ê°€ê²© íŒ¨í„´ë§Œ ì‚¬ìš©
    price_match = re.search(r'(\d{1,3}(?:,\d{3})*)\s*ì›', text)
    if price_match:
        try:
            price = int(price_match.group(1).replace(',', ''))
            if 100 <= price <= 10000000:
                return price
        except:
            pass
    
    return 0

def extract_brand_fast(link, product_name):
    """ë¹ ë¥¸ ë¸Œëœë“œ ì¶”ì¶œ (ê°„ì†Œí™”ëœ ë²„ì „)"""
    try:
        if product_name:
            # ì˜ ì•Œë ¤ì§„ ë¸Œëœë“œë§Œ ë¹ ë¥´ê²Œ í™•ì¸
            known_brands = [
                'APPLE', 'ì‚¼ì„±', 'SAMSUNG', 'LG', 'ë‚˜ì´í‚¤', 'NIKE', 
                'ë†ì‹¬', 'ì˜¤ëšœê¸°', 'ì‚¼ì–‘', 'ì•„ë””ë‹¤ìŠ¤', 'ADIDAS'
            ]
            
            product_upper = product_name.upper()
            for brand in known_brands:
                if brand.upper() in product_upper:
                    return brand
            
            # ì²« ë‹¨ì–´ë§Œ í™•ì¸
            first_word = product_name.split()[0] if product_name.split() else ''
            if first_word and 2 < len(first_word) < 15:
                return first_word
        
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'
        
    except Exception:
        return 'ë¸Œëœë“œ ì •ë³´ ì—†ìŒ'

def get_product_name_from_page_fast(product_url):
    """ê°œë³„ í˜ì´ì§€ì—ì„œ ë¹ ë¥¸ ìƒí’ˆëª… ì¶”ì¶œ"""
    try:
        headers = get_headers()
        response = requests.get(product_url, headers=headers, timeout=3)  # ë§¤ìš° ì§§ì€ íƒ€ì„ì•„ì›ƒ
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ê°€ì¥ í™•ì‹¤í•œ ì„ íƒìë“¤ë§Œ ì‚¬ìš©
        name_selectors = [
            'h2.cdtl_prd_nm',
            'h1.cdtl_prd_nm',
            '.prod_tit',
            '.item_tit'
        ]
        
        for selector in name_selectors:
            name_elem = soup.select_one(selector)
            if name_elem:
                name = name_elem.get_text(strip=True)
                if name and name != "SSG.COM" and len(name) > 10:
                    return name
        
        return None
        
    except Exception:
        return None

def clean_product_name(name):
    """ìƒí’ˆëª… ì •ì œ (ê°•í™”ëœ ë²„ì „)"""
    if not name:
        return name
    
    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    name = re.sub(r'(ë¦¬ë·°\s*\d+|ë³„ì |í• ì¸|ë°°ì†¡)', '', name)
    name = re.sub(r'(ì •ìƒê°€ê²©|íŒë§¤ê°€ê²©|ìµœê³ íŒë§¤ê°€)', '', name)
    name = re.sub(r'(ADADë€\?\s*íˆ´íŒ\s*ì—´ê¸°)', '', name)  # ê´‘ê³  ê´€ë ¨ í…ìŠ¤íŠ¸
    name = re.sub(r'(ê²€ìƒ‰\s*í•„í„°|ë¸Œëœë“œ\s*ì „ì²´ë³´ê¸°)', '', name)  # í•„í„° ê´€ë ¨ í…ìŠ¤íŠ¸
    name = re.sub(r'(\d+ë§Œì›\s*ì´í•˜|\d+ë§Œì›~\d+ë§Œì›)', '', name)  # ê°€ê²© ë²”ìœ„ í…ìŠ¤íŠ¸
    name = re.sub(r'(ì¸ê¸°|BEST|ì¶”ì²œ|ì„ ë¬¼)', '', name)  # ë§ˆì¼€íŒ… í…ìŠ¤íŠ¸
    name = re.sub(r'(ìƒˆë²½ë°°ì†¡|ë‹¹ì¼ë°°ì†¡|ë¬´ë£Œë°°ì†¡)', '', name)  # ë°°ì†¡ ê´€ë ¨
    
    # ì—°ì† ê³µë°± ì œê±°
    name = re.sub(r'\s+', ' ', name).strip()
    
    # ê¸¸ì´ ì œí•œ (ë” ì§§ê²Œ)
    if len(name) > 60:
        name = name[:60] + "..."
    
    return name

def search_ssg_products(keyword, page=1, limit=20):
    """ë©”ì¸ SSG ìƒí’ˆ ê²€ìƒ‰ í•¨ìˆ˜ (ë¹„ë™ê¸° ìš°ì„ , ë™ê¸° í´ë°±)"""
    try:
        if ASYNC_AVAILABLE:
            print("ğŸš€ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ì‚¬ìš©")
            return search_ssg_products_enhanced(keyword, page, limit)
        else:
            print("ğŸŒ ê¸°ì¡´ ë™ê¸° í¬ë¡¤ëŸ¬ ì‚¬ìš©")
            return search_ssg_products_legacy(keyword, page, limit)
    except Exception as e:
        print(f"âš ï¸ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬ ì˜¤ë¥˜, ë™ê¸° í¬ë¡¤ëŸ¬ë¡œ í´ë°±: {e}")
        return search_ssg_products_legacy(keyword, page, limit)

if __name__ == '__main__':
    print("=== SSG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    test_search()
    print("\n=== SSG ê°€ê²© ë¹„êµ í…ŒìŠ¤íŠ¸ ===")
    test_compare()
    print("\n=== ë‹¨ì¼ ìƒí’ˆ í…ŒìŠ¤íŠ¸ ===")
    test_single_product()